{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import getenv\n",
    "from sqlalchemy import create_engine\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pycountry\n",
    "import contextlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_given_var(env_var_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Check if the given environment variable is set and return its value.\n",
    "\n",
    "    Args:\n",
    "        env_var_str (str): The name of the environment variable to check.\n",
    "\n",
    "    Returns:\n",
    "        str: The value of the environment variable.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If the environment variable is not found.\n",
    "    \"\"\"\n",
    "\n",
    "    env_var = getenv(env_var_str)\n",
    "    assert (\n",
    "        env_var is not None\n",
    "    ), f\"{env_var_str} is required but not found in environment variables\"\n",
    "    return env_var\n",
    "\n",
    "\n",
    "def check_env_vars() -> (str, str, str, str):  # type: ignore\n",
    "    user = check_given_var(\"DBL_USER\")\n",
    "    database = check_given_var(\"DBL_DATABASE\")\n",
    "    password = check_given_var(\"DBL_PASSWORD\")\n",
    "    host = check_given_var(\"DBL_HOST\")\n",
    "    return user, database, password, host\n",
    "\n",
    "\n",
    "USER, DATABASE, PASSWORD, HOST = check_env_vars()\n",
    "# Test database runs waaaaaaaaaaaaaaaaaay faster, yet slow\n",
    "# USER, DATABASE = \"nezox2um_test\", \"nezox2um_test\"\n",
    "QUERY_ALL = \"\"\"\n",
    "SELECT \n",
    "    Users.user_id AS user_id, \n",
    "    Users.creation_time AS user_creation_time, \n",
    "    Users.verified,\n",
    "    Users.followers_count,\n",
    "    Users.friends_count,\n",
    "    Users.statuses_count,\n",
    "    Users.default_profile,\n",
    "    Users.default_profile_image,\n",
    "    Tweets.creation_time AS tweet_creation_time,\n",
    "    Tweets.tweet_id,\n",
    "    Tweets.full_text,\n",
    "    Tweets.lang,\n",
    "    Tweets.country_code,\n",
    "    Tweets.favorite_count,\n",
    "    Tweets.retweet_count,\n",
    "    Tweets.possibly_sensitive,\n",
    "    Tweets.replied_tweet_id,\n",
    "    Tweets.reply_count,\n",
    "    Tweets.quoted_status_id,\n",
    "    Tweets.quote_count\n",
    "FROM Users\n",
    "INNER JOIN Tweets ON Users.user_id = Tweets.user_id\n",
    "LIMIT 2000000;\n",
    "\n",
    "\"\"\"\n",
    "DTYPES = {\n",
    "\"user_id\": \"object\",\n",
    "\"user_creation_time\": \"datetime64[ns]\",\n",
    "\"verified\": \"bool\",\n",
    "\"followers_count\": \"int32\",\n",
    "\"friends_count\": \"int32\",\n",
    "\"statuses_count\": \"int32\",\n",
    "\"default_profile\": \"bool\",\n",
    "\"default_profile_image\": \"bool\",\n",
    "\"tweet_creation_time\": \"datetime64[ns]\",\n",
    "\"tweet_id\": \"object\",\n",
    "\"full_text\": \"object\",\n",
    "\"lang\": \"category\",\n",
    "\"country_code\": \"category\",\n",
    "\"favorite_count\": \"int32\",\n",
    "\"retweet_count\": \"int32\",\n",
    "\"possibly_sensitive\": \"bool\",\n",
    "\"replied_tweet_id\": \"object\",\n",
    "\"reply_count\": \"int32\",\n",
    "\"quoted_status_id\": \"object\",\n",
    "\"quote_count\": \"int32\",\n",
    "}\n",
    "\n",
    "COMPANY_NAME_TO_ID = {\n",
    "    \"Klm\": \"56377143\",\n",
    "    \"Air France\": \"106062176\",\n",
    "    \"British Airways\": \"18332190\",\n",
    "    \"American Air\": \"22536055\",\n",
    "    \"Lufthansa\": \"124476322\",\n",
    "    \"Air Berlin\": \"26223583\",\n",
    "    \"Air Berlin assist\": \"2182373406\",\n",
    "    \"easyJet\": \"38676903\",\n",
    "    \"Ryanair\": \"1542862735\",\n",
    "    \"Singapore Airlines\": \"253340062\",\n",
    "    \"Qantas\": \"218730857\",\n",
    "    \"Etihad Airways\": \"45621423\",\n",
    "    \"Virgin Atlantic\": \"20626359\",\n",
    "}\n",
    "\n",
    "COMPANY_ID_TO_NAME = {v: k for k, v in COMPANY_NAME_TO_ID.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(query: str, dtype: bool =True) -> pd.DataFrame:\n",
    "    engine = create_engine(f\"mysql://{USER}:{PASSWORD}@{HOST}:3306/{DATABASE}\")\n",
    "    if dtype:\n",
    "        return pd.read_sql_query(query, engine, dtype=DTYPES, index_col='tweet_id')\n",
    "    return pd.read_sql_query(query, engine)\n",
    "\n",
    "\n",
    "def get_size_of(size_bytes: float | int) -> str:\n",
    "    if size_bytes == 0:\n",
    "        return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    # Using numpy to calculate the logarithm base 1024\n",
    "    i = int(np.floor(np.log(size_bytes) / np.log(1024)))\n",
    "    # Using numpy to calculate power of 1024\n",
    "    p = np.power(1024, i)\n",
    "    # Computing the size division\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return f\"{s} {size_name[i]}\"\n",
    "\n",
    "\n",
    "def identify_dtype(column):\n",
    "    \"\"\"\n",
    "    Identifies the most suitable data type for a pandas Series without loss of information.\n",
    "\n",
    "    Args:\n",
    "    column (pd.Series): The pandas Series for which the data type needs to be identified.\n",
    "\n",
    "    Returns:\n",
    "    str: Suggested data type as a string.\n",
    "    \"\"\"\n",
    "    # Check if the column can be converted to numeric types (int or float)\n",
    "    if pd.api.types.is_numeric_dtype(column):\n",
    "        if not pd.to_numeric(column.dropna(), errors='coerce').notna().all():\n",
    "            return 'object'  # Fallback if numeric conversion fails\n",
    "\n",
    "        if not (column.dropna() % 1 == 0).all():\n",
    "            return 'float'\n",
    "        # Check range to decide between int types\n",
    "        min_val, max_val = column.min(), column.max()\n",
    "        if np.iinfo(np.int8).min <= min_val <= np.iinfo(np.int8).max and max_val <= np.iinfo(np.int8).max:\n",
    "            return 'int8'\n",
    "        elif np.iinfo(np.int16).min <= min_val <= np.iinfo(np.int16).max and max_val <= np.iinfo(np.int16).max:\n",
    "            return 'int16'\n",
    "        elif np.iinfo(np.int32).min <= min_val <= np.iinfo(np.int32).max and max_val <= np.iinfo(np.int32).max:\n",
    "            return 'int32'\n",
    "        else:\n",
    "            return 'int64'\n",
    "    # Check if the column can be converted to datetime\n",
    "    with contextlib.suppress(ValueError, TypeError):\n",
    "        pd.to_datetime(column)\n",
    "        return 'datetime'\n",
    "    # Check if the column should be categorical\n",
    "    if pd.api.types.is_object_dtype(column):\n",
    "        num_unique_values = len(column.unique())\n",
    "        num_total_values = len(column)\n",
    "        if num_unique_values / num_total_values < 0.5:\n",
    "            return 'category'\n",
    "\n",
    "    # Default to object type if none of the above conditions are met\n",
    "    return 'object'\n",
    "\n",
    "\n",
    "def get_full_language_name(language_code, default=\"Unknown Language\"):\n",
    "    \"\"\"\n",
    "    Convert a two-letter language code (ISO 639-1) to its full language name.\n",
    "    \n",
    "    Parameters:\n",
    "    language_code (str): The two-letter ISO 639-1 language code.\n",
    "    \n",
    "    Returns:\n",
    "    str: The full name of the language or a message indicating the code was not found.\n",
    "    \"\"\"\n",
    "    if language_code==\"Other languages\":\n",
    "        return language_code\n",
    "    language = pycountry.languages.get(alpha_2=language_code, default=default)\n",
    "    if language != default:\n",
    "        language = language.name\n",
    "    return language\n",
    "\n",
    "\n",
    "def get_country_name(country_code, default=\"Unknown Country\"):\n",
    "    \"\"\"\n",
    "    Convert a two-letter country code (ISO 3166-1 alpha-2|) to its full country name.\n",
    "    \n",
    "    Parameters:\n",
    "    country_code (str): The two-letter ISO 3166-1 alpha-2 country code.\n",
    "    \n",
    "    Returns:\n",
    "    str: The full name of the country or a message indicating the code was not found.\n",
    "    \"\"\"\n",
    "    country = pycountry.countries.get(alpha_2=country_code, default=default)\n",
    "    if country != default:\n",
    "        country = country.name\n",
    "    return country\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test database runs waaaaaaaaaaaaaaaaaay faster, yet slow\n",
    "# USER, DATABASE = \"nezox2um_test\", \"nezox2um_test\"\n",
    "# import pandas as pd\n",
    "# from sqlalchemy import create_engine\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# def process_data_chunks(query):\n",
    "#     engine = create_engine(f\"mysql://{USER}:{PASSWORD}@{HOST}:3306/{DATABASE}\")\n",
    "#     chunk_size = 100_000\n",
    "#     offset = 0\n",
    "#     df_result = pd.DataFrame()\n",
    "\n",
    "#     # Estimate the total number of rows\n",
    "#     total_rows_query = f\"SELECT COUNT(*) FROM ({query}) AS total\"\n",
    "#     total_rows = pd.read_sql_query(total_rows_query, engine).iloc[0, 0]\n",
    "#     total_chunks = (total_rows // chunk_size) + 1\n",
    "\n",
    "#     # Use tqdm to display the progress bar\n",
    "#     with tqdm(total=total_chunks, desc=\"Processing Data Chunks\") as pbar:\n",
    "#         while True:\n",
    "#             chunk_query = f\"{query} LIMIT {chunk_size} OFFSET {offset}\"\n",
    "#             df_chunk = pd.read_sql_query(chunk_query, engine)\n",
    "#             if df_chunk.empty:\n",
    "#                 break\n",
    "#             # Append the chunk to the list\n",
    "#             df_result = pd.concat([df_result, df_result], ignore_index=True)\n",
    "#             # Update the offset\n",
    "#             offset += chunk_size\n",
    "#             # Update the progress bar\n",
    "#             pbar.update(1)\n",
    "    \n",
    "#     return df_result\n",
    "\n",
    "# # Use the function to get and process data\n",
    "# full_data = process_data_chunks(QUERY_ALL)\n",
    "test_data = fetch_data(QUERY_ALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_size_of(test_data.memory_usage(index=False, deep=True).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_lines = 6511404\n",
    "tweets_right_now = len(test_data)\n",
    "\n",
    "# Example data\n",
    "values = [total_lines, tweets_right_now]\n",
    "labels = [\"Number of possible tweets\", \"Number of stored tweets\"]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "bars = plt.bar(labels, values)\n",
    "\n",
    "# Add labels on top of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2 - 0.1, yval + 5000, f'{yval:,}', fontsize=12, weight='bold')\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Comparison of tweets provided vs stored', fontsize=16, weight='bold')\n",
    "plt.ylabel('Number of Tweets', fontsize=14, weight='bold')\n",
    "plt.xticks(fontsize=12, weight='bold')\n",
    "plt.yticks(fontsize=12, weight='bold');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: what is exact change, for instance, how did deleting no user_id tweets impacted the storage\n",
    "# Example data\n",
    "data = [258, 414685, 190928, 2326, 15]\n",
    "labels = ['Not a tweet', 'Duplicate tweet', 'Inhuman language', 'No tweet id', \"Invalid user\"]\n",
    "\n",
    "# Ensure data and labels have the same length\n",
    "assert len(data) == len(labels), \"Data and labels must be the same length.\"\n",
    "\n",
    "# Sort the data and labels in decreasing order\n",
    "sorted_data_labels = sorted(zip(data, labels), reverse=True)\n",
    "data, labels = zip(*sorted_data_labels)\n",
    "\n",
    "# Choose a color palette\n",
    "\n",
    "# Create the bar chart\n",
    "plt.figure(figsize=(20, 8))\n",
    "bars = plt.bar(labels, data)\n",
    "\n",
    "# Add labels on top of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2 - 0.1, yval + 5000, f'{yval:,}', fontsize=12, weight='bold')\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Numbers of potential tweets not considered per category', fontsize=16, weight='bold')\n",
    "plt.ylabel('Number of Tweets', fontsize=14, weight='bold')\n",
    "plt.xticks(fontsize=12, weight='bold')\n",
    "plt.yticks(fontsize=12, weight='bold');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_lines = 35\n",
    "tweets_right_now = 2.2\n",
    "\n",
    "values = [total_lines, tweets_right_now]\n",
    "labels = [\"Raw data\", \"Filtered data\"]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.bar(labels, values)  \n",
    "\n",
    "# Add labels on top of each bar\n",
    "# for bar in bars:\n",
    "#     yval = bar.get_height()\n",
    "#     plt.text(bar.get_x() + bar.get_width()/2 - 0.1, yval, f'{yval:,}', fontsize=12, weight='bold')\n",
    "\n",
    "# Customize the chart\n",
    "plt.title('Comparison of storage required', fontsize=16, weight='bold')\n",
    "plt.ylabel('Storage, GB', fontsize=14, weight='bold')\n",
    "plt.xticks(fontsize=12, weight='bold')\n",
    "plt.yticks(fontsize=12, weight='bold');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change later to \"un\" instead fo \"und\"\n",
    "lang_popularity_df = test_data.reset_index().groupby('lang', observed=True)\\\n",
    "    .count()[['tweet_id']]\\\n",
    "    .sort_values('tweet_id', ascending=False)\n",
    "# lang_popularity_df.index = lang_popularity_df.index.map(get_full_language_name)\n",
    "lang_popularity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 10\n",
    "\n",
    "# Step 1: Identify the top 10 languages by tweet_id count\n",
    "top_10_languages = lang_popularity_df.nlargest(5, 'tweet_id')\n",
    "\n",
    "# Step 3: Identify the other languages\n",
    "other_languages_df = lang_popularity_df.loc[~lang_popularity_df.index.isin(top_10_languages.index)]\n",
    "\n",
    "# Step 4: Aggregate the tweet_id and fraction for other languages\n",
    "other_languages_agg = other_languages_df.sum()\n",
    "other_languages_agg.name = 'Other languages'\n",
    "\n",
    "# Step 5: Combine the top 10 languages with the aggregated other languages\n",
    "final_df = pd.concat([top_10_languages, other_languages_agg.to_frame().T])\n",
    "final_df.index.name = 'Language'\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your existing code for plotting\n",
    "top_5_popularity_lang_full = final_df.copy()\n",
    "top_5_popularity_lang_full.index = top_5_popularity_lang_full.index.map(get_full_language_name)\n",
    "\n",
    "labels = top_5_popularity_lang_full.index\n",
    "sizes = top_5_popularity_lang_full[\"tweet_id\"]\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140, textprops={'fontsize': 14, 'weight': 'bold'})\n",
    "plt.title('Number of tweets by 5 most popular languages', fontsize=16, weight='bold')\n",
    "plt.legend(labels, title=\"Countries\", bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country of origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change later to \"un\" instead fo \"und\"\n",
    "country_df = test_data.reset_index().groupby('country_code', observed=True).count()[['tweet_id']].sort_values('tweet_id', ascending=False)\n",
    "country_df.index = country_df.index.map(get_country_name)\n",
    "country_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_10_countries = country_df.nlargest(1, 'tweet_id')\n",
    "other_countries_df = country_df.loc[~country_df.index.isin(top_10_countries.index)]\n",
    "other_countries_agg = other_countries_df.sum()\n",
    "\n",
    "other_countries_agg.name = 'Other countries'\n",
    "final_df = pd.concat([top_10_countries, other_countries_agg.to_frame().T])\n",
    "final_df.index.name = 'Country'\n",
    "\n",
    "labels = final_df.index\n",
    "sizes = final_df['tweet_id']\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140, textprops={'fontsize': 14, 'weight': 'bold'})\n",
    "plt.title(\"Number of tweets per known countries\", fontsize=16, weight='bold')\n",
    "plt.legend(labels, title=\"Countries\", bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your existing code for plotting\n",
    "df_plot_by_country = country_df[country_df.index != \"Unknown Country\"].copy()\n",
    "\n",
    "# Step 1: Identify the top 10 languages by tweet_id count\n",
    "top_10_countries = df_plot_by_country.nlargest(5, 'tweet_id')\n",
    "\n",
    "# Step 3: Identify the other languages\n",
    "other_countries_df = df_plot_by_country.loc[~df_plot_by_country.index.isin(top_10_countries.index)]\n",
    "\n",
    "# Step 4: Aggregate the tweet_id and fraction for other languages\n",
    "other_countries_agg = other_countries_df.sum()\n",
    "other_countries_agg.name = 'Other countries'\n",
    "\n",
    "# Step 5: Combine the top 10 languages with the aggregated other languages\n",
    "final_df = pd.concat([top_10_countries, other_countries_agg.to_frame().T])\n",
    "final_df.index.name = 'Country'\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 5))\n",
    "# Prepare data for pie chart\n",
    "labels = final_df.index\n",
    "sizes = final_df['tweet_id']\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140, textprops={'fontsize': 14, 'weight': 'bold'})\n",
    "plt.title(\"Distribution of tweets per known countries\", fontsize=16, weight='bold')\n",
    "plt.legend(labels, title=\"Countries\", bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets from main accounts of the airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avia_names = set(COMPANY_NAME_TO_ID.values())\n",
    "\n",
    "replies_to_avia_companies_df = test_data.loc[test_data['user_id'].apply(lambda x: any(x == avia_name for avia_name in avia_names))]\n",
    "replies_to_avia_companies_df = replies_to_avia_companies_df.reset_index().groupby(\"user_id\").count()[['tweet_id']].sort_values('tweet_id', ascending=False).reset_index()\n",
    "replies_to_avia_companies_df[\"user_id\"] = replies_to_avia_companies_df[\"user_id\"].apply(lambda user_id: COMPANY_ID_TO_NAME.get(user_id, user_id))\n",
    "replies_to_avia_companies_df = replies_to_avia_companies_df.set_index(\"user_id\")\n",
    "replies_to_avia_companies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(25,8))\n",
    "sns.barplot(data=replies_to_avia_companies_df, ax=ax, x='user_id', y='tweet_id')\n",
    "# Customize the chart\n",
    "plt.title('Number of tweets by airline company', fontsize=16, weight='bold')\n",
    "plt.ylabel('Number of tweets', fontsize=14, weight='bold')\n",
    "plt.xlabel('', fontsize=14, weight='bold')\n",
    "plt.xticks(fontsize=12, weight='bold')\n",
    "plt.yticks(fontsize=12, weight='bold');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replies to company posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SQL\n",
    "df_reply = fetch_data(\"\"\"\n",
    "SELECT \n",
    "    t1.tweet_id AS tweet_id,\n",
    "    t1.creation_time AS tweet_creation_time,\n",
    "    t1.user_id AS user_id,\n",
    "    t2.tweet_id AS original_tweet_id,\n",
    "    t2.creation_time AS original_tweet_creation_time,\n",
    "    t2.user_id AS original_user_id\n",
    "FROM \n",
    "    Tweets t1\n",
    "INNER JOIN \n",
    "    Tweets t2\n",
    "ON \n",
    "    t1.replied_tweet_id = t2.tweet_id;\n",
    "\"\"\", dtype=False).set_index(\"tweet_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reply[\"response_time\"] = df_reply[\"tweet_creation_time\"] - df_reply[\"original_tweet_creation_time\"]\n",
    "df_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reply[\"airline\"] = df_reply[\"user_id\"].map(COMPANY_ID_TO_NAME)\n",
    "df_reply[\"original_airline\"] = df_reply[\"original_user_id\"].map(COMPANY_ID_TO_NAME)\n",
    "df_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime and timedelta columns\n",
    "# Convert datetime and timedelta columns\n",
    "df_reply['tweet_creation_time'] = pd.to_datetime(df_reply['tweet_creation_time'])\n",
    "df_reply['original_tweet_creation_time'] = pd.to_datetime(df_reply['original_tweet_creation_time'])\n",
    "df_reply['response_time'] = pd.to_timedelta(df_reply['response_time'])\n",
    "\n",
    "# Calculate average response time per airline\n",
    "average_response_time_airline = df_reply[df_reply['airline'].notnull()].groupby('airline')['response_time'].mean()\n",
    "\n",
    "# Calculate average response time for others users to react to each airline\n",
    "average_response_time_reactions = df_reply[df_reply['original_airline'].notnull()].groupby('original_airline')['response_time'].mean()\n",
    "\n",
    "# Combine the results into one DataFrame for plotting\n",
    "combined_df = pd.DataFrame({\n",
    "    'Airline': average_response_time_airline.index.union(average_response_time_reactions.index),\n",
    "    'Airline Response Time': average_response_time_airline.reindex(average_response_time_airline.index.union(average_response_time_reactions.index)),\n",
    "    'User Reaction Time': average_response_time_reactions.reindex(average_response_time_airline.index.union(average_response_time_reactions.index))\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# Convert timedelta to total seconds for plotting\n",
    "combined_df['Airline Response Time'] = combined_df['Airline Response Time']\n",
    "combined_df['User Reaction Time'] = combined_df['User Reaction Time']\n",
    "combined_df.sort_values(by=['Airline Response Time', 'User Reaction Time'], ascending=[True, False], inplace=True)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_plot = combined_df[combined_df[\"Airline\"] != \"Air Berlin\"].copy()\n",
    "combined_df_plot['Airline Response Time, hours'] = combined_df_plot['Airline Response Time'].dt.total_seconds() / 3600\n",
    "combined_df_plot['User Reaction Time, days'] = combined_df_plot['User Reaction Time'].dt.total_seconds() / 86.400\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(18, 12))\n",
    "sns.barplot(combined_df_plot, x='Airline', y='Airline Response Time, hours', ax=ax[0])\n",
    "ax[0].set_title('Average airline customer service response time', fontsize=16, weight='bold')\n",
    "ax[0].set_ylabel('Airline Response Time, hours', fontsize=14, weight='bold')\n",
    "sns.barplot(combined_df_plot, x='Airline', y='User Reaction Time, days', ax=ax[1])\n",
    "ax[1].set_title('Average user reaction time to airline tweet', fontsize=16, weight='bold')\n",
    "ax[1].set_ylabel('User Reaction Time, days', fontsize=14, weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reply_luft = df_reply.groupby(\"airline\")\n",
    "# df_reply_luft.reset_index().set_index(\"original_tweet_id\")\n",
    "df_reply_luft.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Companies' activity and popularity in social media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_no_index = test_data.reset_index().copy()\n",
    "popularity_by_airlines = test_data_no_index.reset_index().loc[test_data_no_index['user_id']\\\n",
    "    .apply(lambda x: any(x == avia_name for avia_name in avia_names))]\\\n",
    "    .groupby(\"user_id\")\\\n",
    "    .agg(\n",
    "          tweet_number=(\"tweet_id\", \"count\"),\n",
    "          retweet_count=(\"retweet_count\", \"sum\"),\n",
    "          favorite_count=(\"favorite_count\", \"sum\"),\n",
    "          reply_count=(\"reply_count\", \"sum\"),\n",
    "          quote_count=(\"quote_count\", \"sum\"),\n",
    "          ).reset_index()\n",
    "popularity_by_airlines[\"user_id\"] = popularity_by_airlines[\"user_id\"].apply(lambda user_id: COMPANY_ID_TO_NAME.get(user_id, user_id))\n",
    "popularity_by_airlines = popularity_by_airlines.set_index(\"user_id\").sort_values(\"retweet_count\", ascending=False)\n",
    "popularity_by_airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=len(popularity_by_airlines.columns),\n",
    "                       figsize=(20, 6 * len(popularity_by_airlines.columns)))\n",
    "\n",
    "for index, column in enumerate(popularity_by_airlines.columns):\n",
    "    df_column = popularity_by_airlines\n",
    "    sns.barplot(data=df_column, x='user_id', y=column, ax=ax[index])\n",
    "    ax[index].set_title(f\"{column} for each airline\", fontsize=16, weight='bold')\n",
    "    ax[index].set_xlabel(\"\")\n",
    "fig.subplots_adjust(hspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information regarding users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = test_data_no_index.copy().groupby(\"user_id\")\n",
    "df_users = df_users.agg(\n",
    "    user_creation_time=(\"user_creation_time\", \"min\"),\n",
    "    verified=(\"verified\", \"min\"),\n",
    "    followers_count=(\"followers_count\", \"min\"),\n",
    "    friends_count=(\"friends_count\", \"min\"),\n",
    "    statuses_count=(\"statuses_count\", \"min\"),\n",
    "    default_profile=(\"default_profile\", \"min\"),\n",
    "    default_profile_image=(\"default_profile_image\", \"max\"),\n",
    "    first_tweet=(\"tweet_creation_time\", \"min\"),\n",
    "    last_tweet=(\"tweet_creation_time\", \"max\"),\n",
    "    possibly_sensitive=(\"possibly_sensitive\", \"sum\"),\n",
    "    favorite_count=(\"favorite_count\", \"sum\"),\n",
    "    retweet_count=(\"retweet_count\", \"sum\"),\n",
    "    reply_count=(\"reply_count\", \"sum\"),\n",
    "    quote_count=(\"quote_count\", \"sum\"),\n",
    "    lang=(\"lang\", \"first\")\n",
    ")\n",
    "df_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom user \"trustworthiness\" classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verified = df_users.groupby(\"verified\").agg(verified=(\"user_creation_time\", \"count\"))\n",
    "df_verified.plot(kind=\"bar\", title=\"Verified user ratio\", legend=False, figsize=(12, 6))\n",
    "df_verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_profile = df_users.groupby(\"default_profile\").agg(default_profile=(\"user_creation_time\", \"count\"))\n",
    "default_profile.plot(kind=\"bar\", title=\"Has default profile user ratio\", legend=False, figsize=(12, 6))\n",
    "default_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_profile_image = df_users.groupby(\"default_profile_image\").agg(default_profile_image=(\"user_creation_time\", \"count\"))\n",
    "default_profile_image.plot(kind=\"bar\", title=\"Has default profile image user ratio\", legend=False, figsize=(12, 6))\n",
    "default_profile_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users[\"time_to_tweet\"] = df_users[\"first_tweet\"] - df_users[\"user_creation_time\"]\n",
    "df_users[\"time_to_tweet\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensitive = test_data.groupby(\"possibly_sensitive\").count()[[\"user_id\"]]\n",
    "df_sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sensitive.plot(kind=\"bar\", title=\"Possibly sensitive tweets\", legend=False, figsize=(12, 6));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
