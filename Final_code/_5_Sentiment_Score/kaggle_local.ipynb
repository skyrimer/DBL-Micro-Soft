{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:07:44.184185Z","iopub.status.busy":"2024-06-16T07:07:44.183577Z","iopub.status.idle":"2024-06-16T07:07:44.277695Z","shell.execute_reply":"2024-06-16T07:07:44.276875Z","shell.execute_reply.started":"2024-06-16T07:07:44.184156Z"},"trusted":true},"outputs":[],"source":["from tqdm.notebook import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:07:44.279577Z","iopub.status.busy":"2024-06-16T07:07:44.279294Z","iopub.status.idle":"2024-06-16T07:07:45.977706Z","shell.execute_reply":"2024-06-16T07:07:45.976761Z","shell.execute_reply.started":"2024-06-16T07:07:44.279553Z"},"trusted":true},"outputs":[],"source":["import sqlite3\n","from typing import Any, Dict, List, Optional, Tuple, Union\n","\n","import pandas as pd\n","\n","\n","def form_connection_params(local: bool, notebook: bool = False) -> Dict[str, Any]:\n","    \"\"\"\n","    Forms connection parameters based on the local and notebook flags.\n","\n","    Args:\n","        local (bool): Flag indicating whether the connection is local.\n","        notebook (bool, optional): Flag indicating whether the notebook\n","            environment is used. Defaults to False.\n","\n","    Returns:\n","        Dict[str, str]: A dictionary containing connection parameters based on the flags.\n","    \"\"\"\n","    if local:\n","        if notebook:\n","            return {\"file_path\": \"/kaggle/working/local_backup (9).db\"}\n","\n","\n","def connect_to_database(\n","    connection_params: Dict[str, str], local: bool\n",") -> Union[sqlite3.Connection]:\n","    \"\"\"\n","    Connects to a database based on the provided connection parameters and local flag.\n","\n","    Args:\n","        connection_params (Dict[str, str]): The parameters required to establish the database connection.\n","        local (bool): Flag indicating whether the connection should be local (SQLite) or remote (MySQL).\n","\n","    Returns:\n","        Union[sqlite3.Connection, mysql.connector.MySQLConnection]: The database connection object if successful.\n","\n","    Raises:\n","        Error: If an error occurs during the connection process.\n","    \"\"\"\n","    if local:\n","        return sqlite3.connect(connection_params[\"file_path\"])\n","\n","\n","def execute_queries(\n","    connection: Union[sqlite3.Connection],\n","    queries: List[Union[str, Tuple[str, List[Tuple[Any]]]]],\n",") -> None:\n","    \"\"\"\n","    Executes a list of SQL queries on the provided database connection.\n","\n","    Args:\n","        connection: The database connection object.\n","        queries (List[Union[str, Tuple[str, List[Tuple[Any]]]]): A list of SQL\n","            queries to execute, where each query can be a string or a tuple\n","            containing the SQL query and parameters.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    cursor = connection.cursor()\n","    for query in queries:\n","        if isinstance(query, str):\n","            cursor.execute(query)\n","        else:\n","            sql, params = query\n","            cursor.executemany(sql, params)\n","    connection.commit()\n","\n","\n","def get_dataframe_from_query(\n","    query: str,\n","    connection_params: Dict[str, str],\n","    local: bool,\n","    dtypes: Optional[Dict[str, str]] = None,\n","    index_col: Optional[str] = None,\n","    parse_dates: Optional[List[str]] = None,\n",") -> pd.DataFrame:\n","    \"\"\"\n","    Retrieves a pandas DataFrame by executing a query on a database connection.\n","\n","    Args:\n","        query (str): The SQL query to execute.\n","        connection_params (Dict[str, str]): The parameters required to establish the database connection.\n","        local (bool): Flag indicating whether the connection is local (SQLite) or remote (MySQL).\n","        dtypes (Optional[Dict[str, str]], optional): Dictionary specifying column data types.\n","            Defaults to None.\n","        index_col (Optional[str], optional): Name of the column to set as the index.\n","            Defaults to None.\n","        parse_dates (Optional[List[str]], optional): List of columns to parse as dates.\n","            Defaults to None.\n","\n","    Returns:\n","        pd.DataFrame: A pandas DataFrame containing the results of the query.\n","    \"\"\"\n","    if parse_dates:\n","        dtypes = {k: v for k, v in (dtypes or {}).items() if k not in parse_dates}\n","\n","    with sqlite3.connect(connection_params[\"file_path\"]) as connection:\n","        return pd.read_sql_query(\n","            query,\n","            connection,\n","            dtype=dtypes,\n","            index_col=index_col,\n","            parse_dates=parse_dates,\n","        )\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:07:45.980585Z","iopub.status.busy":"2024-06-16T07:07:45.980051Z","iopub.status.idle":"2024-06-16T07:08:09.440127Z","shell.execute_reply":"2024-06-16T07:08:09.439227Z","shell.execute_reply.started":"2024-06-16T07:07:45.980551Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-16 07:07:47.774383: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-16 07:07:47.774504: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-16 07:07:47.915977: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b1624f327984350bf44d457947a4983","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb242308a0eb4e3295d38d6935f76a11","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"240df77a54b845c0a63b3059128eba09","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf389e903e0342b79d99bb129f1b723f","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6debc90d7d984aed8d6c88f63190273a","version_major":2,"version_minor":0},"text/plain":["tf_model.h5:   0%|          | 0.00/501M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n","\n","All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["Physical devices cannot be modified after being initialized\n"]}],"source":["import contextlib\n","import gc\n","import os\n","import re\n","import string\n","import sys\n","from concurrent.futures import ThreadPoolExecutor\n","from typing import List, Tuple\n","\n","import pandas as pd\n","import tensorflow as tf\n","from scipy.special import softmax\n","from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n","\n","# Load the tokenizer and model\n","model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = TFAutoModelForSequenceClassification.from_pretrained(\n","    \"cardiffnlp/twitter-roberta-base-sentiment\"\n",")\n","if physical_devices := tf.config.list_physical_devices(\"GPU\"):\n","    try:\n","        for device in physical_devices:\n","            tf.config.experimental.set_memory_growth(device, True)\n","    except RuntimeError as e:\n","        print(e)\n","\n","device = \"/GPU:0\" if tf.config.list_physical_devices(\"GPU\") else \"/CPU:0\"\n","\n","\n","def process_batch(texts):\n","    \"\"\"\n","    Apply sentiment analysis to a batch of texts using a pre-trained transformer model.\n","\n","    Parameters:\n","    texts (list): A list of texts to analyze.\n","\n","    Returns:\n","    list: A list of ranked sentiment labels for the input texts.\n","\n","    This function uses a pre-trained transformer model for sequence classification to analyze the sentiment of the texts in the given batch. It returns a list of ranked sentiment labels for the input texts, where the first label is the most likely sentiment and the subsequent labels are less likely sentiments.\n","    \"\"\"\n","    # Get the maximum sequence length for the model\n","    encoded_input = tokenizer(\n","        texts, return_tensors=\"tf\", padding=True, truncation=True, max_length=512\n","    )\n","    with tf.device(device):\n","        output = model(encoded_input)\n","\n","    scores = output[0].numpy()\n","    scores = softmax(scores, axis=1)\n","\n","    sentiment_scores = scores[:, 2] - scores[:, 0]\n","    return sentiment_scores.tolist()\n","\n","\n","def clear_gpu_memory():\n","    tf.keras.backend.clear_session()  # Clear the current session\n","    with contextlib.suppress(AttributeError):\n","        tf.compat.v1.reset_default_graph()  # For TensorFlow 1.x compatibility\n","    gc.collect()  # Explicitly call the garbage collector\n","\n","\n","def apply_sentiment_analysis(\n","    df: pd.DataFrame, text_column: str, batch_size=128, max_workers=4\n","):\n","    \"\"\"\n","    Apply sentiment analysis to the given DataFrame using a pre-trained transformer model.\n","\n","    Parameters:\n","    df (pd.DataFrame): The input DataFrame containing the text column to analyze.\n","    text_column (str): The name of the column in the DataFrame containing the text to analyze.\n","    batch_size (int): The number of texts to process in each batch. Default is 128.\n","    max_workers (int): The maximum number of worker threads to use for parallel processing. Default is 4.\n","\n","    Returns:\n","    pd.DataFrame: The input DataFrame with an additional 'sentiment' column containing the sentiment analysis results.\n","\n","    This function uses a pre-trained transformer model for sequence classification\n","    to analyze the sentiment of the texts in the given DataFrame. It applies the\n","    sentiment analysis in parallel using multiple worker threads to improve performance.\n","    The results are then added to the input DataFrame as a new 'sentiment' column.\n","    \"\"\"\n","    texts = df[text_column].tolist()\n","    results = []\n","\n","    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n","        for i in range(0, len(texts), batch_size):\n","            batch = texts[i : i + batch_size]\n","            results.extend(executor.submit(process_batch, batch).result())\n","            clear_gpu_memory()\n","    df[\"sentiment\"] = results\n","    return df\n","\n","\n","def clean_mentions(tweet):\n","    # Remove RT since it has no meaning\n","    tweet = re.sub(r\"^RT \", \"\", tweet)\n","    # Remove URLs since they should not impact anything\n","    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", tweet)\n","    # Remove user mentions\n","    tweet = re.sub(r\"@\\w+\", \"\", tweet)\n","    # Remove hashtag symbols but keep the words\n","    tweet = re.sub(r\"#\", \"\", tweet)\n","    # Remove unnecessary punctuation while keeping emoticons and important punctuation\n","    tweet = tweet.translate(\n","        str.maketrans(\n","            \"\",\n","            \"\",\n","            string.punctuation.replace(\"!\", \"\").replace(\"?\", \"\").replace(\"#\", \"\"),\n","        )\n","    )\n","    # Strip unnecessary whitespace\n","    return tweet.strip()\n","\n","\n","def update_sentiment_scores(\n","    batch: List[Tuple[str, str]], connection_params: dict, local: bool\n",") -> None:\n","    \"\"\"\n","    Update full_text values for a batch of data in the local SQLite database.\n","\n","    Args:\n","        batch: List of (full_text, tweet_id) pairs.\n","        db_path: The path to the SQLite database file.\n","    \"\"\"\n","    update_query = \"UPDATE Tweets SET sentiment_score = ? WHERE tweet_id = ?\"\n","    if not local:\n","        update_query = update_query.replace(\"?\", \"%s\")\n","    with connect_to_database(connection_params, local) as connection:\n","        execute_queries(connection, [(update_query, batch)])\n","        connection.commit()\n","\n","\n","def get_batches(df: pd.DataFrame, batch_size: int = 1000) -> List[pd.DataFrame]:\n","    \"\"\"\n","    Split DataFrame into batches of DataFrames with specified batch size.\n","\n","    Args:\n","        df: The DataFrame containing tweet data.\n","        batch_size: The size of each batch.\n","\n","    Returns:\n","        A list of DataFrames, each containing a batch of rows.\n","    \"\"\"\n","    return [df.iloc[i : i + batch_size] for i in range(0, len(df), batch_size)]\n","\n","\n","def convert_to_list(df: pd.DataFrame) -> List[List]:\n","    \"\"\"\n","    Convert DataFrame with tweet_id as index to a list of lists containing sentiment and tweet_id.\n","\n","    Args:\n","        df: The DataFrame with tweet_id as index and sentiment as a column.\n","\n","    Returns:\n","        A list of lists containing tweet_id and sentiment.\n","    \"\"\"\n","    tweet_ids = df.index.to_numpy()\n","    sentiments = df[\"sentiment\"].to_numpy()\n","    return tuple(zip(sentiments, tweet_ids))"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:08:09.441663Z","iopub.status.busy":"2024-06-16T07:08:09.441280Z","iopub.status.idle":"2024-06-16T07:08:09.446693Z","shell.execute_reply":"2024-06-16T07:08:09.445722Z","shell.execute_reply.started":"2024-06-16T07:08:09.441629Z"},"trusted":true},"outputs":[],"source":["local = True\n","connection_params = form_connection_params(local, True)\n","query = \"\"\"\n","SELECT tweet_id, full_text\n","FROM Tweets\n","WHERE sentiment_score IS NULL;\n","\"\"\"\n","batch_size = 10_000"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:08:09.449420Z","iopub.status.busy":"2024-06-16T07:08:09.449128Z","iopub.status.idle":"2024-06-16T07:08:26.092012Z","shell.execute_reply":"2024-06-16T07:08:26.090929Z","shell.execute_reply.started":"2024-06-16T07:08:09.449385Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid, fd = os.forkpty()\n"]}],"source":["!cp \"/kaggle/input/dbl-sentiment-update/local_backup (9).db\" \"/kaggle/working/\""]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:08:26.094230Z","iopub.status.busy":"2024-06-16T07:08:26.093708Z","iopub.status.idle":"2024-06-16T07:08:32.247316Z","shell.execute_reply":"2024-06-16T07:08:32.246416Z","shell.execute_reply.started":"2024-06-16T07:08:26.094184Z"},"trusted":true},"outputs":[],"source":["test_data = get_dataframe_from_query(query, connection_params, local, index_col=\"tweet_id\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:08:32.249291Z","iopub.status.busy":"2024-06-16T07:08:32.248626Z","iopub.status.idle":"2024-06-16T07:09:20.894549Z","shell.execute_reply":"2024-06-16T07:09:20.893514Z","shell.execute_reply.started":"2024-06-16T07:08:32.249255Z"},"trusted":true},"outputs":[],"source":["# Apply the cleaning function to the DataFrame\n","test_data['cleaned_text'] = test_data['full_text'].apply(clean_mentions)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:09:20.896110Z","iopub.status.busy":"2024-06-16T07:09:20.895802Z","iopub.status.idle":"2024-06-16T07:09:20.917478Z","shell.execute_reply":"2024-06-16T07:09:20.916510Z","shell.execute_reply.started":"2024-06-16T07:09:20.896085Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>full_text</th>\n","      <th>cleaned_text</th>\n","    </tr>\n","    <tr>\n","      <th>tweet_id</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1212599633509277697</th>\n","      <td>This is so crazyðŸ˜©</td>\n","      <td>This is so crazyðŸ˜©</td>\n","    </tr>\n","    <tr>\n","      <th>1212599644984926210</th>\n","      <td>RT @andrewkimmel: Dear @AmericanAir,\\n\\nAfter ...</td>\n","      <td>Dear \\n\\nAfter arriving back to LA from Indone...</td>\n","    </tr>\n","    <tr>\n","      <th>1212599647157526530</th>\n","      <td>RT @JamesHasson20: The lack of self-awareness ...</td>\n","      <td>The lack of selfawareness in this thread is hi...</td>\n","    </tr>\n","    <tr>\n","      <th>1212599702933258240</th>\n","      <td>RT @blexijade: This thread lol https://t.co/vj...</td>\n","      <td>This thread lol</td>\n","    </tr>\n","    <tr>\n","      <th>1212599704401395717</th>\n","      <td>RT @andrewkimmel: Dear @AmericanAir,\\n\\nAfter ...</td>\n","      <td>Dear \\n\\nAfter arriving back to LA from Indone...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1244696703690772485</th>\n","      <td>RT @jfergo86: Me parece a mÃ­ o el aviÃ³n es mÃ¡s...</td>\n","      <td>Me parece a mÃ­ o el aviÃ³n es mÃ¡s grande que el...</td>\n","    </tr>\n","    <tr>\n","      <th>1244696708983984131</th>\n","      <td>Todayâ€™s random pic of the day is the one of Vo...</td>\n","      <td>Todayâ€™s random pic of the day is the one of Vo...</td>\n","    </tr>\n","    <tr>\n","      <th>1244696710447800320</th>\n","      <td>RT @SchipholWatch: @spbverhagen @markduursma @...</td>\n","      <td>Nog niet aan de orde? Als in er is nog geen st...</td>\n","    </tr>\n","    <tr>\n","      <th>1244696713350217728</th>\n","      <td>RT @wiltingklaas: Tweede Kamer stemt over vlie...</td>\n","      <td>Tweede Kamer stemt over vliegtaks  via  Of ze ...</td>\n","    </tr>\n","    <tr>\n","      <th>1244696713765564416</th>\n","      <td>@easyJet My refund is being process since two ...</td>\n","      <td>My refund is being process since two weeks ago...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2293105 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["                                                             full_text  \\\n","tweet_id                                                                 \n","1212599633509277697                                  This is so crazyðŸ˜©   \n","1212599644984926210  RT @andrewkimmel: Dear @AmericanAir,\\n\\nAfter ...   \n","1212599647157526530  RT @JamesHasson20: The lack of self-awareness ...   \n","1212599702933258240  RT @blexijade: This thread lol https://t.co/vj...   \n","1212599704401395717  RT @andrewkimmel: Dear @AmericanAir,\\n\\nAfter ...   \n","...                                                                ...   \n","1244696703690772485  RT @jfergo86: Me parece a mÃ­ o el aviÃ³n es mÃ¡s...   \n","1244696708983984131  Todayâ€™s random pic of the day is the one of Vo...   \n","1244696710447800320  RT @SchipholWatch: @spbverhagen @markduursma @...   \n","1244696713350217728  RT @wiltingklaas: Tweede Kamer stemt over vlie...   \n","1244696713765564416  @easyJet My refund is being process since two ...   \n","\n","                                                          cleaned_text  \n","tweet_id                                                                \n","1212599633509277697                                  This is so crazyðŸ˜©  \n","1212599644984926210  Dear \\n\\nAfter arriving back to LA from Indone...  \n","1212599647157526530  The lack of selfawareness in this thread is hi...  \n","1212599702933258240                                    This thread lol  \n","1212599704401395717  Dear \\n\\nAfter arriving back to LA from Indone...  \n","...                                                                ...  \n","1244696703690772485  Me parece a mÃ­ o el aviÃ³n es mÃ¡s grande que el...  \n","1244696708983984131  Todayâ€™s random pic of the day is the one of Vo...  \n","1244696710447800320  Nog niet aan de orde? Als in er is nog geen st...  \n","1244696713350217728  Tweede Kamer stemt over vliegtaks  via  Of ze ...  \n","1244696713765564416  My refund is being process since two weeks ago...  \n","\n","[2293105 rows x 2 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["test_data"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:09:20.919610Z","iopub.status.busy":"2024-06-16T07:09:20.919049Z","iopub.status.idle":"2024-06-16T07:09:21.430853Z","shell.execute_reply":"2024-06-16T07:09:21.429833Z","shell.execute_reply.started":"2024-06-16T07:09:20.919576Z"},"trusted":true},"outputs":[],"source":["data_batches = get_batches(test_data[[\"cleaned_text\"]], batch_size)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-16T07:09:21.432260Z","iopub.status.busy":"2024-06-16T07:09:21.431985Z","iopub.status.idle":"2024-06-16T07:27:53.143552Z","shell.execute_reply":"2024-06-16T07:27:53.142379Z","shell.execute_reply.started":"2024-06-16T07:09:21.432237Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15fab9b255054187a22f5d21987b8cf5","version_major":2,"version_minor":0},"text/plain":["Updating sentiment_score:   0%|          | 0/2294 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(data_batches, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpdating sentiment_score: \u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# feel free to change the \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     df_sentiment \u001b[38;5;241m=\u001b[39m \u001b[43mapply_sentiment_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcleaned_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     update_sentiment_scores(convert_to_list(df_sentiment), connection_params, local)\n","Cell \u001b[0;32mIn[3], line 90\u001b[0m, in \u001b[0;36mapply_sentiment_analysis\u001b[0;34m(df, text_column, batch_size, max_workers)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(texts), batch_size):\n\u001b[1;32m     89\u001b[0m         batch \u001b[38;5;241m=\u001b[39m texts[i : i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m---> 90\u001b[0m         results\u001b[38;5;241m.\u001b[39mextend(\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     91\u001b[0m         clear_gpu_memory()\n\u001b[1;32m     92\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m results\n","File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n","File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["for batch in tqdm(data_batches, desc=\"Updating sentiment_score: \"):\n","    # feel free to change the \n","    df_sentiment = apply_sentiment_analysis(batch, \"cleaned_text\", 128, 2)\n","    update_sentiment_scores(convert_to_list(df_sentiment), connection_params, local)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5219636,"sourceId":8702643,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
