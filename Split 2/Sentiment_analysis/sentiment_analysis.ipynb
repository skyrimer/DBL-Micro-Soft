{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sqlalchemy import create_engine\n",
    "# v1\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_given_var(env_var_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Check if the given environment variable is set and return its value.\n",
    "\n",
    "    Args:\n",
    "        env_var_str (str): The name of the environment variable to check.\n",
    "\n",
    "    Returns:\n",
    "        str: The value of the environment variable.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If the environment variable is not found.\n",
    "    \"\"\"\n",
    "\n",
    "    env_var = os.getenv(env_var_str)\n",
    "    assert (\n",
    "        env_var is not None\n",
    "    ), f\"{env_var_str} is required but not found in environment variables\"\n",
    "    return env_var\n",
    "\n",
    "\n",
    "def check_env_vars() -> (str, str, str, str):  # type: ignore\n",
    "    user = check_given_var(\"DBL_USER\")\n",
    "    database = check_given_var(\"DBL_DATABASE\")\n",
    "    password = check_given_var(\"DBL_PASSWORD\")\n",
    "    host = check_given_var(\"DBL_HOST\")\n",
    "    return user, database, password, host\n",
    "\n",
    "\n",
    "USER, DATABASE, PASSWORD, HOST = check_env_vars()\n",
    "# USER, DATABASE = \"nezox2um_test\", \"nezox2um_test\"\n",
    "QUERY_ALL = \"\"\"\n",
    "SELECT \n",
    "    Users.user_id AS user_id, \n",
    "    Users.creation_time AS user_creation_time, \n",
    "    Tweets.creation_time AS tweet_creation_time,\n",
    "    Tweets.tweet_id,\n",
    "    Tweets.full_text,\n",
    "    Tweets.lang,\n",
    "    Tweets.replied_tweet_id\n",
    "FROM Users\n",
    "INNER JOIN Tweets ON Users.user_id = Tweets.user_id;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "DTYPES = {\n",
    "\"user_id\": \"object\",\n",
    "\"tweet_id\": \"object\",\n",
    "\"full_text\": \"object\",\n",
    "\"lang\": \"category\",\n",
    "\"replied_tweet_id\": \"object\",\n",
    "}\n",
    "\n",
    "COMPANY_NAME_TO_ID = {\n",
    "    \"Klm\": \"56377143\",\n",
    "    \"Air France\": \"106062176\",\n",
    "    \"British Airways\": \"18332190\",\n",
    "    \"American Air\": \"22536055\",\n",
    "    \"Lufthansa\": \"124476322\",\n",
    "    \"Air Berlin\": \"26223583\",\n",
    "    \"Air Berlin assist\": \"2182373406\",\n",
    "    \"easyJet\": \"38676903\",\n",
    "    \"Ryanair\": \"1542862735\",\n",
    "    \"Singapore Airlines\": \"253340062\",\n",
    "    \"Qantas\": \"218730857\",\n",
    "    \"Etihad Airways\": \"45621423\",\n",
    "    \"Virgin Atlantic\": \"20626359\",\n",
    "}\n",
    "\n",
    "COMPANY_ID_TO_NAME = {v: k for k, v in COMPANY_NAME_TO_ID.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_data(query: str, path: str, dtype: bool = True) -> pd.DataFrame:\n",
    "    # Connect to the SQLite database using a context manager\n",
    "    with sqlite3.connect(path) as connection:\n",
    "        # Read the data into a DataFrame\n",
    "        if dtype:\n",
    "            df = pd.read_sql_query(query, connection,\n",
    "                                   dtype=DTYPES,\n",
    "                                   index_col='tweet_id')\n",
    "            df['tweet_creation_time'] = pd.to_datetime(df['tweet_creation_time'])\n",
    "            df['user_creation_time'] = pd.to_datetime(df['user_creation_time'])\n",
    "        else:\n",
    "            df = pd.read_sql_query(query, connection)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def fetch_data(query: str, dtype: bool = True) -> pd.DataFrame:\n",
    "    engine = create_engine(f\"mysql://{USER}:{PASSWORD}@{HOST}:3306/{DATABASE}\")\n",
    "    if dtype:\n",
    "        return pd.read_sql_query(query, engine,\n",
    "                                 dtype=DTYPES, index_col='tweet_id')\n",
    "    return pd.read_sql_query(query, engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Server\n",
    "# test_data = fetch_data(QUERY_ALL)\n",
    "# Local\n",
    "path =  os.path.join(\n",
    "    os.path.dirname(\n",
    "        os.path.dirname(\n",
    "            os.getcwd()\n",
    "            )\n",
    "        ),\n",
    "    \"data_processed\", \"local_backup.db\")\n",
    "\n",
    "test_data = get_local_data(QUERY_ALL, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>replied_tweet_id</th>\n",
       "      <th>tweet_creation_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1131172858951024641</th>\n",
       "      <td>393374091</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-05-22 12:20:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130922003702177800</th>\n",
       "      <td>880417607865815040</td>\n",
       "      <td>1130615560910254080</td>\n",
       "      <td>2019-05-21 19:43:11+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131172864147808257</th>\n",
       "      <td>3420691215</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-05-22 12:20:01+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131172867985485824</th>\n",
       "      <td>394376606</td>\n",
       "      <td>1131032916232826881</td>\n",
       "      <td>2019-05-22 12:20:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131030279278063616</th>\n",
       "      <td>227687574</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-05-22 02:53:26+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244696703690772485</th>\n",
       "      <td>278698748</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-03-30 18:43:14+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244696708983984131</th>\n",
       "      <td>246520593</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-03-30 18:43:15+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244696710447800320</th>\n",
       "      <td>109284383</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-03-30 18:43:15+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244696713350217728</th>\n",
       "      <td>1223576386432126976</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-03-30 18:43:16+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244696713765564416</th>\n",
       "      <td>56784613</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-03-30 18:43:16+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6148105 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 user_id     replied_tweet_id  \\\n",
       "tweet_id                                                        \n",
       "1131172858951024641            393374091                 None   \n",
       "1130922003702177800   880417607865815040  1130615560910254080   \n",
       "1131172864147808257           3420691215                 None   \n",
       "1131172867985485824            394376606  1131032916232826881   \n",
       "1131030279278063616            227687574                 None   \n",
       "...                                  ...                  ...   \n",
       "1244696703690772485            278698748                 None   \n",
       "1244696708983984131            246520593                 None   \n",
       "1244696710447800320            109284383                 None   \n",
       "1244696713350217728  1223576386432126976                 None   \n",
       "1244696713765564416             56784613                 None   \n",
       "\n",
       "                          tweet_creation_time  \n",
       "tweet_id                                       \n",
       "1131172858951024641 2019-05-22 12:20:00+00:00  \n",
       "1130922003702177800 2019-05-21 19:43:11+00:00  \n",
       "1131172864147808257 2019-05-22 12:20:01+00:00  \n",
       "1131172867985485824 2019-05-22 12:20:02+00:00  \n",
       "1131030279278063616 2019-05-22 02:53:26+00:00  \n",
       "...                                       ...  \n",
       "1244696703690772485 2020-03-30 18:43:14+00:00  \n",
       "1244696708983984131 2020-03-30 18:43:15+00:00  \n",
       "1244696710447800320 2020-03-30 18:43:15+00:00  \n",
       "1244696713350217728 2020-03-30 18:43:16+00:00  \n",
       "1244696713765564416 2020-03-30 18:43:16+00:00  \n",
       "\n",
       "[6148105 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_special = test_data[[\"user_id\", \"replied_tweet_id\", \"tweet_creation_time\"]]\n",
    "convo_special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = defaultdict(TrieNode)\n",
    "        self.is_end = False\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()\n",
    "\n",
    "    def insert(self, conversation):\n",
    "        node = self.root\n",
    "        for tweet_id in conversation:\n",
    "            node = node.children[tweet_id]\n",
    "        node.is_end = True\n",
    "\n",
    "    def is_subset(self, conversation):\n",
    "        node = self.root\n",
    "        for tweet_id in conversation:\n",
    "            if tweet_id not in node.children:\n",
    "                return False\n",
    "            node = node.children[tweet_id]\n",
    "        return True\n",
    "\n",
    "def trace_conversation(start_tweet_id: str, tweet_dict: dict):\n",
    "    convo = []\n",
    "    current_tweet_id = start_tweet_id\n",
    "    users_in_conversation = set()\n",
    "    local_processed_tweet_ids = set()  # Local set to track the current conversation\n",
    "    while current_tweet_id:\n",
    "        if current_tweet_id not in tweet_dict or current_tweet_id in local_processed_tweet_ids:\n",
    "            break\n",
    "        tweet_info = tweet_dict[current_tweet_id]\n",
    "        convo.append(current_tweet_id)\n",
    "        users_in_conversation.add(tweet_info['user_id'])\n",
    "        local_processed_tweet_ids.add(current_tweet_id)\n",
    "        if len(users_in_conversation) > 2:\n",
    "            return convo[:-1][::-1]  # As soon as the third user appears, we delete his tweet and return\n",
    "        current_tweet_id = tweet_info['replied_tweet_id']\n",
    "    return convo[::-1] if len(users_in_conversation) == 2 else None\n",
    "\n",
    "def extract_and_filter_conversations(df: pd.DataFrame):\n",
    "    df = df.sort_values(\"tweet_creation_time\", ascending=False)\n",
    "    df.index = df.index.astype(str)\n",
    "    tweet_dict = df.to_dict('index')\n",
    "    conversations = []\n",
    "    trie = Trie()  # Initialize trie for subset checks\n",
    "\n",
    "    # Start tracing conversations from tweets that are replies\n",
    "    for tweet_id in tqdm(df[df['replied_tweet_id'].notnull()].index, desc=\"Extracting all conversations\"):\n",
    "        if conversation := trace_conversation(tweet_id, tweet_dict):\n",
    "            if not trie.is_subset(conversation):\n",
    "                trie.insert(conversation)\n",
    "                conversations.append(conversation)\n",
    "\n",
    "    return conversations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting all conversations: 100%|██████████| 1795409/1795409 [00:07<00:00, 256295.28it/s]\n"
     ]
    }
   ],
   "source": [
    "conversations = extract_and_filter_conversations(convo_special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation</th>\n",
       "      <th>Tweet_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1244694453190897664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1244696682979303426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1244677304598609923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1244696641401163776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1244648694454026240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712242</th>\n",
       "      <td>1064150</td>\n",
       "      <td>451125255294443521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712243</th>\n",
       "      <td>1064151</td>\n",
       "      <td>430790355962052608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712244</th>\n",
       "      <td>1064151</td>\n",
       "      <td>430792524043931648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712245</th>\n",
       "      <td>1064152</td>\n",
       "      <td>248528541157834752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712246</th>\n",
       "      <td>1064152</td>\n",
       "      <td>248529937198366720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2712247 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Conversation             Tweet_ID\n",
       "0                   1  1244694453190897664\n",
       "1                   1  1244696682979303426\n",
       "2                   2  1244677304598609923\n",
       "3                   2  1244696641401163776\n",
       "4                   3  1244648694454026240\n",
       "...               ...                  ...\n",
       "2712242       1064150   451125255294443521\n",
       "2712243       1064151   430790355962052608\n",
       "2712244       1064151   430792524043931648\n",
       "2712245       1064152   248528541157834752\n",
       "2712246       1064152   248529937198366720\n",
       "\n",
       "[2712247 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for convo_num, convo in enumerate(conversations, start=1):\n",
    "    data.extend((convo_num, tweet_id) for tweet_id in convo)\n",
    "# Create a DataFrame\n",
    "df_conversations = pd.DataFrame(data, columns=['Conversation', 'Tweet_ID'])\n",
    "\n",
    "# Set MultiIndex\n",
    "df_conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_creation_time</th>\n",
       "      <th>tweet_creation_time</th>\n",
       "      <th>full_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>replied_tweet_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conversation</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1244694453190897664</th>\n",
       "      <td>521835883</td>\n",
       "      <td>2012-03-12 01:11:22+00:00</td>\n",
       "      <td>2020-03-30 18:34:17+00:00</td>\n",
       "      <td>@nealrach @VirginAtlantic Siiiigh.... Still no...</td>\n",
       "      <td>en</td>\n",
       "      <td>1243885949697888263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244696682979303426</th>\n",
       "      <td>20626359</td>\n",
       "      <td>2009-02-11 20:50:56+00:00</td>\n",
       "      <td>2020-03-30 18:43:09+00:00</td>\n",
       "      <td>@Jade_Velveteese Hi Jade. We have an ‘Away fro...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244694453190897664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1244677304598609923</th>\n",
       "      <td>396021583</td>\n",
       "      <td>2011-10-22 16:35:05+00:00</td>\n",
       "      <td>2020-03-30 17:26:09+00:00</td>\n",
       "      <td>@VirginAtlantic Sod off your primary sharehold...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244669964289806338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244696641401163776</th>\n",
       "      <td>832964639436701696</td>\n",
       "      <td>2017-02-18 14:47:00+00:00</td>\n",
       "      <td>2020-03-30 18:42:59+00:00</td>\n",
       "      <td>@Boyde11 @VirginAtlantic Get your facts right,...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244677304598609923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>1244648694454026240</th>\n",
       "      <td>1233410199500791809</td>\n",
       "      <td>2020-02-28 15:14:56+00:00</td>\n",
       "      <td>2020-03-30 15:32:27+00:00</td>\n",
       "      <td>@flavioArCab @Chapux0204 @chechiffss @aeronaut...</td>\n",
       "      <td>es</td>\n",
       "      <td>1244643427515535360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064150</th>\n",
       "      <th>451125255294443521</th>\n",
       "      <td>22536055</td>\n",
       "      <td>2009-03-02 21:23:05+00:00</td>\n",
       "      <td>2014-04-01 22:33:37+00:00</td>\n",
       "      <td>@lanaupdates_ Your information has been forwar...</td>\n",
       "      <td>en</td>\n",
       "      <td>451124070730719233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1064151</th>\n",
       "      <th>430790355962052608</th>\n",
       "      <td>64327804</td>\n",
       "      <td>2009-08-10 03:34:27+00:00</td>\n",
       "      <td>2014-02-04 19:49:59+00:00</td>\n",
       "      <td>@AmericanAir phew, they finally turned on the ...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430792524043931648</th>\n",
       "      <td>22536055</td>\n",
       "      <td>2009-03-02 21:23:05+00:00</td>\n",
       "      <td>2014-02-04 19:58:36+00:00</td>\n",
       "      <td>@benjy_greenberg It looks like we'll have you ...</td>\n",
       "      <td>en</td>\n",
       "      <td>430790355962052608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1064152</th>\n",
       "      <th>248528541157834752</th>\n",
       "      <td>19911051</td>\n",
       "      <td>2009-02-02 15:17:02+00:00</td>\n",
       "      <td>2012-09-19 21:06:36+00:00</td>\n",
       "      <td>Un-fucking believable!\\nThanks @BritishAirways...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248529937198366720</th>\n",
       "      <td>399494759</td>\n",
       "      <td>2011-10-27 15:47:03+00:00</td>\n",
       "      <td>2012-09-19 21:12:09+00:00</td>\n",
       "      <td>@djmarkknight @britishairways i have have the ...</td>\n",
       "      <td>en</td>\n",
       "      <td>248528541157834752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2712247 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              user_id  \\\n",
       "Conversation Tweet_ID                                   \n",
       "1            1244694453190897664            521835883   \n",
       "             1244696682979303426             20626359   \n",
       "2            1244677304598609923            396021583   \n",
       "             1244696641401163776   832964639436701696   \n",
       "3            1244648694454026240  1233410199500791809   \n",
       "...                                               ...   \n",
       "1064150      451125255294443521              22536055   \n",
       "1064151      430790355962052608              64327804   \n",
       "             430792524043931648              22536055   \n",
       "1064152      248528541157834752              19911051   \n",
       "             248529937198366720             399494759   \n",
       "\n",
       "                                        user_creation_time  \\\n",
       "Conversation Tweet_ID                                        \n",
       "1            1244694453190897664 2012-03-12 01:11:22+00:00   \n",
       "             1244696682979303426 2009-02-11 20:50:56+00:00   \n",
       "2            1244677304598609923 2011-10-22 16:35:05+00:00   \n",
       "             1244696641401163776 2017-02-18 14:47:00+00:00   \n",
       "3            1244648694454026240 2020-02-28 15:14:56+00:00   \n",
       "...                                                    ...   \n",
       "1064150      451125255294443521  2009-03-02 21:23:05+00:00   \n",
       "1064151      430790355962052608  2009-08-10 03:34:27+00:00   \n",
       "             430792524043931648  2009-03-02 21:23:05+00:00   \n",
       "1064152      248528541157834752  2009-02-02 15:17:02+00:00   \n",
       "             248529937198366720  2011-10-27 15:47:03+00:00   \n",
       "\n",
       "                                       tweet_creation_time  \\\n",
       "Conversation Tweet_ID                                        \n",
       "1            1244694453190897664 2020-03-30 18:34:17+00:00   \n",
       "             1244696682979303426 2020-03-30 18:43:09+00:00   \n",
       "2            1244677304598609923 2020-03-30 17:26:09+00:00   \n",
       "             1244696641401163776 2020-03-30 18:42:59+00:00   \n",
       "3            1244648694454026240 2020-03-30 15:32:27+00:00   \n",
       "...                                                    ...   \n",
       "1064150      451125255294443521  2014-04-01 22:33:37+00:00   \n",
       "1064151      430790355962052608  2014-02-04 19:49:59+00:00   \n",
       "             430792524043931648  2014-02-04 19:58:36+00:00   \n",
       "1064152      248528541157834752  2012-09-19 21:06:36+00:00   \n",
       "             248529937198366720  2012-09-19 21:12:09+00:00   \n",
       "\n",
       "                                                                          full_text  \\\n",
       "Conversation Tweet_ID                                                                 \n",
       "1            1244694453190897664  @nealrach @VirginAtlantic Siiiigh.... Still no...   \n",
       "             1244696682979303426  @Jade_Velveteese Hi Jade. We have an ‘Away fro...   \n",
       "2            1244677304598609923  @VirginAtlantic Sod off your primary sharehold...   \n",
       "             1244696641401163776  @Boyde11 @VirginAtlantic Get your facts right,...   \n",
       "3            1244648694454026240  @flavioArCab @Chapux0204 @chechiffss @aeronaut...   \n",
       "...                                                                             ...   \n",
       "1064150      451125255294443521   @lanaupdates_ Your information has been forwar...   \n",
       "1064151      430790355962052608   @AmericanAir phew, they finally turned on the ...   \n",
       "             430792524043931648   @benjy_greenberg It looks like we'll have you ...   \n",
       "1064152      248528541157834752   Un-fucking believable!\\nThanks @BritishAirways...   \n",
       "             248529937198366720   @djmarkknight @britishairways i have have the ...   \n",
       "\n",
       "                                 lang     replied_tweet_id  \n",
       "Conversation Tweet_ID                                       \n",
       "1            1244694453190897664   en  1243885949697888263  \n",
       "             1244696682979303426   en  1244694453190897664  \n",
       "2            1244677304598609923   en  1244669964289806338  \n",
       "             1244696641401163776   en  1244677304598609923  \n",
       "3            1244648694454026240   es  1244643427515535360  \n",
       "...                               ...                  ...  \n",
       "1064150      451125255294443521    en   451124070730719233  \n",
       "1064151      430790355962052608    en                 None  \n",
       "             430792524043931648    en   430790355962052608  \n",
       "1064152      248528541157834752    en                 None  \n",
       "             248529937198366720    en   248528541157834752  \n",
       "\n",
       "[2712247 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Merge the conversation DataFrame with the test_data DataFrame\n",
    "df_conversations_full = df_conversations.merge(test_data, left_on='Tweet_ID', right_index=True, how='left')\n",
    "\n",
    "# Set the MultiIndex again with Conversation and Tweet_ID\n",
    "df_conversations_full.set_index(['Conversation', 'Tweet_ID'], inplace=True)\n",
    "df_conversations_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_creation_time</th>\n",
       "      <th>tweet_creation_time</th>\n",
       "      <th>full_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>replied_tweet_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conversation</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">140</th>\n",
       "      <th>1244658051740774400</th>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-30 16:09:38+00:00</td>\n",
       "      <td>@thick_daddy The online cancellation tool will...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244650317494566913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244688840033546245</th>\n",
       "      <td>119901222</td>\n",
       "      <td>2010-03-04 22:18:43+00:00</td>\n",
       "      <td>2020-03-30 18:11:59+00:00</td>\n",
       "      <td>@lufthansa @thick_daddy I received the same em...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244658051740774400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244691330837762051</th>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-30 18:21:53+00:00</td>\n",
       "      <td>@NateThomasNOLA @thick_daddy At the moment, my...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244688840033546245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">194</th>\n",
       "      <th>1244684192040071173</th>\n",
       "      <td>62555545</td>\n",
       "      <td>2009-08-03 16:35:21+00:00</td>\n",
       "      <td>2020-03-30 17:53:31+00:00</td>\n",
       "      <td>@lufthansa had an email stating changes to my ...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244688444162486273</th>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-30 18:10:24+00:00</td>\n",
       "      <td>@Holgate1987 At the moment, my colleagues in t...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244684192040071173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064013</th>\n",
       "      <th>1095473044573700096</th>\n",
       "      <td>1339792290</td>\n",
       "      <td>2013-04-09 17:56:30+00:00</td>\n",
       "      <td>2019-02-13 00:01:41+00:00</td>\n",
       "      <td>@lufthansa Read on @YahooNews you sued a guy f...</td>\n",
       "      <td>en</td>\n",
       "      <td>1094985662384594944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1064019</th>\n",
       "      <th>1090912573304774662</th>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2019-01-31 10:00:00+00:00</td>\n",
       "      <td>With 297 seats, the #A340-600 is next in line ...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090913775417479168</th>\n",
       "      <td>18631142</td>\n",
       "      <td>2009-01-05 13:13:10+00:00</td>\n",
       "      <td>2019-01-31 10:04:46+00:00</td>\n",
       "      <td>@lufthansa 747-400, then 747-8, then A380. :)</td>\n",
       "      <td>en</td>\n",
       "      <td>1090912573304774662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1064028</th>\n",
       "      <th>1083376699780280321</th>\n",
       "      <td>478699784</td>\n",
       "      <td>2012-01-30 15:32:40+00:00</td>\n",
       "      <td>2019-01-10 14:55:08+00:00</td>\n",
       "      <td>Hi @lufthansa how come there is no 'Ms' option...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083381532071469058</th>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2019-01-10 15:14:20+00:00</td>\n",
       "      <td>@JosephPKilroy The \"Ms\" option is supposed to ...</td>\n",
       "      <td>en</td>\n",
       "      <td>1083376699780280321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44091 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     user_id        user_creation_time  \\\n",
       "Conversation Tweet_ID                                                    \n",
       "140          1244658051740774400   124476322 2010-03-19 14:30:32+00:00   \n",
       "             1244688840033546245   119901222 2010-03-04 22:18:43+00:00   \n",
       "             1244691330837762051   124476322 2010-03-19 14:30:32+00:00   \n",
       "194          1244684192040071173    62555545 2009-08-03 16:35:21+00:00   \n",
       "             1244688444162486273   124476322 2010-03-19 14:30:32+00:00   \n",
       "...                                      ...                       ...   \n",
       "1064013      1095473044573700096  1339792290 2013-04-09 17:56:30+00:00   \n",
       "1064019      1090912573304774662   124476322 2010-03-19 14:30:32+00:00   \n",
       "             1090913775417479168    18631142 2009-01-05 13:13:10+00:00   \n",
       "1064028      1083376699780280321   478699784 2012-01-30 15:32:40+00:00   \n",
       "             1083381532071469058   124476322 2010-03-19 14:30:32+00:00   \n",
       "\n",
       "                                       tweet_creation_time  \\\n",
       "Conversation Tweet_ID                                        \n",
       "140          1244658051740774400 2020-03-30 16:09:38+00:00   \n",
       "             1244688840033546245 2020-03-30 18:11:59+00:00   \n",
       "             1244691330837762051 2020-03-30 18:21:53+00:00   \n",
       "194          1244684192040071173 2020-03-30 17:53:31+00:00   \n",
       "             1244688444162486273 2020-03-30 18:10:24+00:00   \n",
       "...                                                    ...   \n",
       "1064013      1095473044573700096 2019-02-13 00:01:41+00:00   \n",
       "1064019      1090912573304774662 2019-01-31 10:00:00+00:00   \n",
       "             1090913775417479168 2019-01-31 10:04:46+00:00   \n",
       "1064028      1083376699780280321 2019-01-10 14:55:08+00:00   \n",
       "             1083381532071469058 2019-01-10 15:14:20+00:00   \n",
       "\n",
       "                                                                          full_text  \\\n",
       "Conversation Tweet_ID                                                                 \n",
       "140          1244658051740774400  @thick_daddy The online cancellation tool will...   \n",
       "             1244688840033546245  @lufthansa @thick_daddy I received the same em...   \n",
       "             1244691330837762051  @NateThomasNOLA @thick_daddy At the moment, my...   \n",
       "194          1244684192040071173  @lufthansa had an email stating changes to my ...   \n",
       "             1244688444162486273  @Holgate1987 At the moment, my colleagues in t...   \n",
       "...                                                                             ...   \n",
       "1064013      1095473044573700096  @lufthansa Read on @YahooNews you sued a guy f...   \n",
       "1064019      1090912573304774662  With 297 seats, the #A340-600 is next in line ...   \n",
       "             1090913775417479168      @lufthansa 747-400, then 747-8, then A380. :)   \n",
       "1064028      1083376699780280321  Hi @lufthansa how come there is no 'Ms' option...   \n",
       "             1083381532071469058  @JosephPKilroy The \"Ms\" option is supposed to ...   \n",
       "\n",
       "                                 lang     replied_tweet_id  \n",
       "Conversation Tweet_ID                                       \n",
       "140          1244658051740774400   en  1244650317494566913  \n",
       "             1244688840033546245   en  1244658051740774400  \n",
       "             1244691330837762051   en  1244688840033546245  \n",
       "194          1244684192040071173   en                 None  \n",
       "             1244688444162486273   en  1244684192040071173  \n",
       "...                               ...                  ...  \n",
       "1064013      1095473044573700096   en  1094985662384594944  \n",
       "1064019      1090912573304774662   en                 None  \n",
       "             1090913775417479168   en  1090912573304774662  \n",
       "1064028      1083376699780280321   en                 None  \n",
       "             1083381532071469058   en  1083376699780280321  \n",
       "\n",
       "[44091 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_conversation = df_conversations_full.loc[df_conversations_full.index.get_level_values('Conversation').isin(df_conversations_full[df_conversations_full['user_id'] == COMPANY_NAME_TO_ID[\"Lufthansa\"]].index.get_level_values('Conversation'))]\n",
    "airline_conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Conversation</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_creation_time</th>\n",
       "      <th>tweet_creation_time</th>\n",
       "      <th>full_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>replied_tweet_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New_Conversation</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>1244658051740774400</th>\n",
       "      <td>140</td>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-30 16:09:38+00:00</td>\n",
       "      <td>@thick_daddy The online cancellation tool will...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244650317494566913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244688840033546245</th>\n",
       "      <td>140</td>\n",
       "      <td>119901222</td>\n",
       "      <td>2010-03-04 22:18:43+00:00</td>\n",
       "      <td>2020-03-30 18:11:59+00:00</td>\n",
       "      <td>@lufthansa @thick_daddy I received the same em...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244658051740774400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244691330837762051</th>\n",
       "      <td>140</td>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-30 18:21:53+00:00</td>\n",
       "      <td>@NateThomasNOLA @thick_daddy At the moment, my...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244688840033546245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1244684192040071173</th>\n",
       "      <td>194</td>\n",
       "      <td>62555545</td>\n",
       "      <td>2009-08-03 16:35:21+00:00</td>\n",
       "      <td>2020-03-30 17:53:31+00:00</td>\n",
       "      <td>@lufthansa had an email stating changes to my ...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244688444162486273</th>\n",
       "      <td>194</td>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-30 18:10:24+00:00</td>\n",
       "      <td>@Holgate1987 At the moment, my colleagues in t...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244684192040071173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14271</th>\n",
       "      <th>1095473044573700096</th>\n",
       "      <td>1064013</td>\n",
       "      <td>1339792290</td>\n",
       "      <td>2013-04-09 17:56:30+00:00</td>\n",
       "      <td>2019-02-13 00:01:41+00:00</td>\n",
       "      <td>@lufthansa Read on @YahooNews you sued a guy f...</td>\n",
       "      <td>en</td>\n",
       "      <td>1094985662384594944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">14272</th>\n",
       "      <th>1090912573304774662</th>\n",
       "      <td>1064019</td>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2019-01-31 10:00:00+00:00</td>\n",
       "      <td>With 297 seats, the #A340-600 is next in line ...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090913775417479168</th>\n",
       "      <td>1064019</td>\n",
       "      <td>18631142</td>\n",
       "      <td>2009-01-05 13:13:10+00:00</td>\n",
       "      <td>2019-01-31 10:04:46+00:00</td>\n",
       "      <td>@lufthansa 747-400, then 747-8, then A380. :)</td>\n",
       "      <td>en</td>\n",
       "      <td>1090912573304774662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">14273</th>\n",
       "      <th>1083376699780280321</th>\n",
       "      <td>1064028</td>\n",
       "      <td>478699784</td>\n",
       "      <td>2012-01-30 15:32:40+00:00</td>\n",
       "      <td>2019-01-10 14:55:08+00:00</td>\n",
       "      <td>Hi @lufthansa how come there is no 'Ms' option...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083381532071469058</th>\n",
       "      <td>1064028</td>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2019-01-10 15:14:20+00:00</td>\n",
       "      <td>@JosephPKilroy The \"Ms\" option is supposed to ...</td>\n",
       "      <td>en</td>\n",
       "      <td>1083376699780280321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44091 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Conversation     user_id  \\\n",
       "New_Conversation Tweet_ID                                        \n",
       "1                1244658051740774400           140   124476322   \n",
       "                 1244688840033546245           140   119901222   \n",
       "                 1244691330837762051           140   124476322   \n",
       "2                1244684192040071173           194    62555545   \n",
       "                 1244688444162486273           194   124476322   \n",
       "...                                            ...         ...   \n",
       "14271            1095473044573700096       1064013  1339792290   \n",
       "14272            1090912573304774662       1064019   124476322   \n",
       "                 1090913775417479168       1064019    18631142   \n",
       "14273            1083376699780280321       1064028   478699784   \n",
       "                 1083381532071469058       1064028   124476322   \n",
       "\n",
       "                                            user_creation_time  \\\n",
       "New_Conversation Tweet_ID                                        \n",
       "1                1244658051740774400 2010-03-19 14:30:32+00:00   \n",
       "                 1244688840033546245 2010-03-04 22:18:43+00:00   \n",
       "                 1244691330837762051 2010-03-19 14:30:32+00:00   \n",
       "2                1244684192040071173 2009-08-03 16:35:21+00:00   \n",
       "                 1244688444162486273 2010-03-19 14:30:32+00:00   \n",
       "...                                                        ...   \n",
       "14271            1095473044573700096 2013-04-09 17:56:30+00:00   \n",
       "14272            1090912573304774662 2010-03-19 14:30:32+00:00   \n",
       "                 1090913775417479168 2009-01-05 13:13:10+00:00   \n",
       "14273            1083376699780280321 2012-01-30 15:32:40+00:00   \n",
       "                 1083381532071469058 2010-03-19 14:30:32+00:00   \n",
       "\n",
       "                                           tweet_creation_time  \\\n",
       "New_Conversation Tweet_ID                                        \n",
       "1                1244658051740774400 2020-03-30 16:09:38+00:00   \n",
       "                 1244688840033546245 2020-03-30 18:11:59+00:00   \n",
       "                 1244691330837762051 2020-03-30 18:21:53+00:00   \n",
       "2                1244684192040071173 2020-03-30 17:53:31+00:00   \n",
       "                 1244688444162486273 2020-03-30 18:10:24+00:00   \n",
       "...                                                        ...   \n",
       "14271            1095473044573700096 2019-02-13 00:01:41+00:00   \n",
       "14272            1090912573304774662 2019-01-31 10:00:00+00:00   \n",
       "                 1090913775417479168 2019-01-31 10:04:46+00:00   \n",
       "14273            1083376699780280321 2019-01-10 14:55:08+00:00   \n",
       "                 1083381532071469058 2019-01-10 15:14:20+00:00   \n",
       "\n",
       "                                                                              full_text  \\\n",
       "New_Conversation Tweet_ID                                                                 \n",
       "1                1244658051740774400  @thick_daddy The online cancellation tool will...   \n",
       "                 1244688840033546245  @lufthansa @thick_daddy I received the same em...   \n",
       "                 1244691330837762051  @NateThomasNOLA @thick_daddy At the moment, my...   \n",
       "2                1244684192040071173  @lufthansa had an email stating changes to my ...   \n",
       "                 1244688444162486273  @Holgate1987 At the moment, my colleagues in t...   \n",
       "...                                                                                 ...   \n",
       "14271            1095473044573700096  @lufthansa Read on @YahooNews you sued a guy f...   \n",
       "14272            1090912573304774662  With 297 seats, the #A340-600 is next in line ...   \n",
       "                 1090913775417479168      @lufthansa 747-400, then 747-8, then A380. :)   \n",
       "14273            1083376699780280321  Hi @lufthansa how come there is no 'Ms' option...   \n",
       "                 1083381532071469058  @JosephPKilroy The \"Ms\" option is supposed to ...   \n",
       "\n",
       "                                     lang     replied_tweet_id  \n",
       "New_Conversation Tweet_ID                                       \n",
       "1                1244658051740774400   en  1244650317494566913  \n",
       "                 1244688840033546245   en  1244658051740774400  \n",
       "                 1244691330837762051   en  1244688840033546245  \n",
       "2                1244684192040071173   en                 None  \n",
       "                 1244688444162486273   en  1244684192040071173  \n",
       "...                                   ...                  ...  \n",
       "14271            1095473044573700096   en  1094985662384594944  \n",
       "14272            1090912573304774662   en                 None  \n",
       "                 1090913775417479168   en  1090912573304774662  \n",
       "14273            1083376699780280321   en                 None  \n",
       "                 1083381532071469058   en  1083376699780280321  \n",
       "\n",
       "[44091 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_conversation = airline_conversation.reset_index()\n",
    "airline_conversation['New_Conversation'] = pd.factorize(airline_conversation['Conversation'])[0] + 1\n",
    "airline_conversation = airline_conversation.set_index(['New_Conversation', 'Tweet_ID'])\n",
    "airline_conversation = airline_conversation.sort_index(level='New_Conversation')\n",
    "airline_conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\My programs\\Python 3.12\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nTFAutoModelForSequenceClassification requires the TensorFlow library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://www.tensorflow.org/install and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcardiffnlp/twitter-roberta-base-sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTFAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcardiffnlp/twitter-roberta-base-sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#Check if GPU is available\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mtest\u001b[38;5;241m.\u001b[39mis_gpu_available():\n",
      "File \u001b[1;32mc:\\My programs\\Python 3.12\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1475\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1475\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\My programs\\Python 3.12\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1463\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1461\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[0;32m   1462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[1;32m-> 1463\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[1;31mImportError\u001b[0m: \nTFAutoModelForSequenceClassification requires the TensorFlow library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://www.tensorflow.org/install and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "#Load the tokenizer and model once\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "#Check if GPU is available\n",
    "if tf.test.is_gpu_available():\n",
    "    device = '/GPU:0'\n",
    "else:\n",
    "    device = '/CPU:0'\n",
    "\n",
    "#Set the labels for sentiment results\n",
    "labels = {\n",
    "    0 : 'negative',\n",
    "    1 : 'neutral',\n",
    "    2 : 'positive'\n",
    "}\n",
    "\n",
    "def process_batch(texts):\n",
    "    \"\"\"\n",
    "    Apply sentiment analysis to a batch of texts using a pre-trained transformer model.\n",
    "\n",
    "    Parameters:\n",
    "    texts (list): A list of texts to analyze.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of ranked sentiment labels for the input texts.\n",
    "\n",
    "    This function uses a pre-trained transformer model for sequence classification to analyze the sentiment of the texts in the given batch. It returns a list of ranked sentiment labels for the input texts, where the first label is the most likely sentiment and the subsequent labels are less likely sentiments.\n",
    "    \"\"\"\n",
    "    encoded_input = tokenizer(texts, return_tensors='tf', padding=True, truncation=True)\n",
    "    with tf.device(device):\n",
    "        output = model(encoded_input)\n",
    "\n",
    "    scores = output[0].numpy()\n",
    "    scores = softmax(scores, axis=1)\n",
    "\n",
    "    sentiment_scores = scores[:, 2] - scores[:, 0]\n",
    "    return sentiment_scores.tolist()\n",
    "\n",
    "def apply_sentiment_analysis(df, text_column, batch_size=64, max_workers=4):\n",
    "    \"\"\"\n",
    "    Apply sentiment analysis to the given DataFrame using a pre-trained transformer model.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame containing the text column to analyze.\n",
    "    text_column (str): The name of the column in the DataFrame containing the text to analyze.\n",
    "    batch_size (int): The number of texts to process in each batch. Default is 128.\n",
    "    max_workers (int): The maximum number of worker threads to use for parallel processing. Default is 4.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The input DataFrame with an additional 'sentiment' column containing the sentiment analysis results.\n",
    "\n",
    "    This function uses a pre-trained transformer model for sequence classification to analyze the sentiment of the texts in the given DataFrame. It applies the sentiment analysis in parallel using multiple worker threads to improve performance. The results are then added to the input DataFrame as a new 'sentiment' column.\n",
    "    \"\"\"\n",
    "    texts = df[text_column].tolist()\n",
    "    results = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            results.extend(executor.submit(process_batch, batch).result())\n",
    "\n",
    "    df['sentiment'] = results\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)  \n",
    "full_text_df = airline_conversation[['full_text']].copy()\n",
    "airline_conversation_sample = full_text_df.head(5)\n",
    "airline_conversation_sample = apply_sentiment_analysis(airline_conversation_sample, 'full_text')\n",
    "airline_conversation_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from typing import Tuple, List\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def connect_to_database(user: str, database: str, password: str, host: str):\n",
    "    \"\"\"\n",
    "    Establish a connection to the database.\n",
    "    \n",
    "    Args:\n",
    "        user: The database user.\n",
    "        database: The name of the database.\n",
    "        password: The password for the database.\n",
    "        host: The database host.\n",
    "    \n",
    "    Returns:\n",
    "        A connection object to the MySQL database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            user=user,\n",
    "            password=password,\n",
    "            host=host,\n",
    "            database=database\n",
    "        )\n",
    "        if connection.is_connected():\n",
    "            return connection\n",
    "    except Error as e:\n",
    "        print(f\"Error while connecting to MySQL: {e}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_batches(df: pd.DataFrame, batch_size: int = 1000) -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Split DataFrame into batches of DataFrames with specified batch size.\n",
    "    \n",
    "    Args:\n",
    "        df: The DataFrame containing tweet data.\n",
    "        batch_size: The size of each batch.\n",
    "        \n",
    "    Returns:\n",
    "        A list of DataFrames, each containing a batch of rows.\n",
    "    \"\"\"\n",
    "    return [df.iloc[i:i + batch_size] for i in range(0, len(df), batch_size)]\n",
    "\n",
    "def update_sentiment_batch(user: str, database: str, password: str, host: str, batch: List[Tuple[str, float]]):\n",
    "    \"\"\"\n",
    "    Update sentiment values for a batch of data in the database.\n",
    "    \n",
    "    Args:\n",
    "        user: The database user.\n",
    "        database: The name of the database.\n",
    "        password: The password for the database.\n",
    "        host: The database host.\n",
    "        batch: A list of tuples containing tweet_id and sentiment.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        connection = connect_to_database(user, database, password, host)\n",
    "        if connection is None:\n",
    "            return\n",
    "        cursor = connection.cursor()\n",
    "        update_query = \"UPDATE Tweets SET sentiment_score = %s WHERE tweet_id = %s\"\n",
    "        cursor.executemany(update_query, batch)\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    except Error as e:\n",
    "        print(f\"Error updating batch: {e}\")\n",
    "\n",
    "def upload_sentiment(batch: Tuple[Tuple[float, str]],\n",
    "                     user: str, database: str, password: str,\n",
    "                     host: str) -> None:\n",
    "    \"\"\"\n",
    "    Create and insert batches of tweets into the database in parallel.\n",
    "    \n",
    "    Args:\n",
    "        batches_list: Tuple of (sentiment, tweet_id) pairs.\n",
    "        user: The database user.\n",
    "        database: The name of the database.\n",
    "        password: The password for the database.\n",
    "        host: The database host.\n",
    "    \"\"\"\n",
    "    connection = connect_to_database(user, database, password, host)\n",
    "    if connection is None:\n",
    "        return\n",
    "    cursor = connection.cursor()\n",
    "    update_query = \"UPDATE Tweets SET sentiment_score = %s WHERE tweet_id = %s\"\n",
    "    cursor.executemany(update_query, batch)\n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "\n",
    "    print(\"Sentiment values updated successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(df: pd.DataFrame) -> List[List]:\n",
    "    \"\"\"\n",
    "    Convert DataFrame with tweet_id as index to a list of lists containing sentiment and tweet_id.\n",
    "    \n",
    "    Args:\n",
    "        df: The DataFrame with tweet_id as index and sentiment as a column.\n",
    "        \n",
    "    Returns:\n",
    "        A list of lists containing tweet_id and sentiment.\n",
    "    \"\"\"\n",
    "    tweet_ids = df.index.to_numpy()\n",
    "    sentiments = df['sentiment'].to_numpy()\n",
    "    return tuple(zip(sentiments, tweet_ids))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batches = get_batches(test_data[[\"full_text\"]], 10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user, database, password, host = os.getenv(\"DBL_USER\"), os.getenv(\"DBL_DATABASE\"), os.getenv(\"DBL_PASSWORD\"), os.getenv(\"DBL_HOST\")\n",
    "for batch in tqdm(data_batches):\n",
    "    sentiment_with_score = apply_sentiment_analysis(batch, \"full_text\")\n",
    "    upload_sentiment(convert_to_list(sentiment_with_score), user, database, password, host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
