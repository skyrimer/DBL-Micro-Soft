{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-02 19:26:50.948661: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/jokubas/anaconda3/envs/new_fucking_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sqlalchemy import create_engine\n",
    "# v1\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_given_var(env_var_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Check if the given environment variable is set and return its value.\n",
    "\n",
    "    Args:\n",
    "        env_var_str (str): The name of the environment variable to check.\n",
    "\n",
    "    Returns:\n",
    "        str: The value of the environment variable.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If the environment variable is not found.\n",
    "    \"\"\"\n",
    "\n",
    "    env_var = os.getenv(env_var_str)\n",
    "    assert (\n",
    "        env_var is not None\n",
    "    ), f\"{env_var_str} is required but not found in environment variables\"\n",
    "    return env_var\n",
    "\n",
    "\n",
    "def check_env_vars() -> (str, str, str, str):  # type: ignore\n",
    "    user = check_given_var(\"DBL_USER\")\n",
    "    database = check_given_var(\"DBL_DATABASE\")\n",
    "    password = check_given_var(\"DBL_PASSWORD\")\n",
    "    host = check_given_var(\"DBL_HOST\")\n",
    "    return user, database, password, host\n",
    "\n",
    "\n",
    "USER, DATABASE, PASSWORD, HOST = check_env_vars()\n",
    "# USER, DATABASE = \"nezox2um_test\", \"nezox2um_test\"\n",
    "QUERY_ALL = \"\"\"\n",
    "SELECT \n",
    "    Users.user_id AS user_id, \n",
    "    Users.creation_time AS user_creation_time, \n",
    "    Tweets.creation_time AS tweet_creation_time,\n",
    "    Tweets.tweet_id,\n",
    "    Tweets.full_text,\n",
    "    Tweets.lang,\n",
    "    Tweets.replied_tweet_id\n",
    "FROM Users\n",
    "INNER JOIN Tweets ON Users.user_id = Tweets.user_id;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "DTYPES = {\n",
    "\"user_id\": \"object\",\n",
    "\"tweet_id\": \"object\",\n",
    "\"full_text\": \"object\",\n",
    "\"lang\": \"category\",\n",
    "\"replied_tweet_id\": \"object\",\n",
    "}\n",
    "\n",
    "COMPANY_NAME_TO_ID = {\n",
    "    \"Klm\": \"56377143\",\n",
    "    \"Air France\": \"106062176\",\n",
    "    \"British Airways\": \"18332190\",\n",
    "    \"American Air\": \"22536055\",\n",
    "    \"Lufthansa\": \"124476322\",\n",
    "    \"Air Berlin\": \"26223583\",\n",
    "    \"Air Berlin assist\": \"2182373406\",\n",
    "    \"easyJet\": \"38676903\",\n",
    "    \"Ryanair\": \"1542862735\",\n",
    "    \"Singapore Airlines\": \"253340062\",\n",
    "    \"Qantas\": \"218730857\",\n",
    "    \"Etihad Airways\": \"45621423\",\n",
    "    \"Virgin Atlantic\": \"20626359\",\n",
    "}\n",
    "\n",
    "COMPANY_ID_TO_NAME = {v: k for k, v in COMPANY_NAME_TO_ID.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_data(query: str, path: str, dtype: bool = True) -> pd.DataFrame:\n",
    "    # Connect to the SQLite database using a context manager\n",
    "    with sqlite3.connect(path) as connection:\n",
    "        # Read the data into a DataFrame\n",
    "        if dtype:\n",
    "            df = pd.read_sql_query(query, connection,\n",
    "                                   dtype=DTYPES,\n",
    "                                   index_col='tweet_id')\n",
    "            df['tweet_creation_time'] = pd.to_datetime(df['tweet_creation_time'])\n",
    "            df['user_creation_time'] = pd.to_datetime(df['user_creation_time'])\n",
    "        else:\n",
    "            df = pd.read_sql_query(query, connection)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def fetch_data(query: str, dtype: bool = True) -> pd.DataFrame:\n",
    "    engine = create_engine(f\"mysql://{USER}:{PASSWORD}@{HOST}:3306/{DATABASE}\")\n",
    "    if dtype:\n",
    "        return pd.read_sql_query(query, engine,\n",
    "                                 dtype=DTYPES, index_col='tweet_id')\n",
    "    return pd.read_sql_query(query, engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Server\n",
    "# test_data = fetch_data(QUERY_ALL)\n",
    "# Local\n",
    "path =  os.path.join(\n",
    "    os.path.dirname(\n",
    "        os.path.dirname(\n",
    "            os.getcwd()\n",
    "            )\n",
    "        ),\n",
    "    \"data_processed\", \"local_backup.db\")\n",
    "\n",
    "test_data = get_local_data(QUERY_ALL, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>replied_tweet_id</th>\n",
       "      <th>tweet_creation_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1131172858951024641</th>\n",
       "      <td>393374091</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-05-22 12:20:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130922003702177800</th>\n",
       "      <td>880417607865815040</td>\n",
       "      <td>1130615560910254080</td>\n",
       "      <td>2019-05-21 19:43:11+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131172864147808257</th>\n",
       "      <td>3420691215</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-05-22 12:20:01+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131172867985485824</th>\n",
       "      <td>394376606</td>\n",
       "      <td>1131032916232826881</td>\n",
       "      <td>2019-05-22 12:20:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131030279278063616</th>\n",
       "      <td>227687574</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-05-22 02:53:26+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244696703690772485</th>\n",
       "      <td>278698748</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-03-30 18:43:14+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244696708983984131</th>\n",
       "      <td>246520593</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-03-30 18:43:15+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244696710447800320</th>\n",
       "      <td>109284383</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-03-30 18:43:15+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244696713350217728</th>\n",
       "      <td>1223576386432126976</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-03-30 18:43:16+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244696713765564416</th>\n",
       "      <td>56784613</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-03-30 18:43:16+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6148105 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 user_id     replied_tweet_id  \\\n",
       "tweet_id                                                        \n",
       "1131172858951024641            393374091                 None   \n",
       "1130922003702177800   880417607865815040  1130615560910254080   \n",
       "1131172864147808257           3420691215                 None   \n",
       "1131172867985485824            394376606  1131032916232826881   \n",
       "1131030279278063616            227687574                 None   \n",
       "...                                  ...                  ...   \n",
       "1244696703690772485            278698748                 None   \n",
       "1244696708983984131            246520593                 None   \n",
       "1244696710447800320            109284383                 None   \n",
       "1244696713350217728  1223576386432126976                 None   \n",
       "1244696713765564416             56784613                 None   \n",
       "\n",
       "                          tweet_creation_time  \n",
       "tweet_id                                       \n",
       "1131172858951024641 2019-05-22 12:20:00+00:00  \n",
       "1130922003702177800 2019-05-21 19:43:11+00:00  \n",
       "1131172864147808257 2019-05-22 12:20:01+00:00  \n",
       "1131172867985485824 2019-05-22 12:20:02+00:00  \n",
       "1131030279278063616 2019-05-22 02:53:26+00:00  \n",
       "...                                       ...  \n",
       "1244696703690772485 2020-03-30 18:43:14+00:00  \n",
       "1244696708983984131 2020-03-30 18:43:15+00:00  \n",
       "1244696710447800320 2020-03-30 18:43:15+00:00  \n",
       "1244696713350217728 2020-03-30 18:43:16+00:00  \n",
       "1244696713765564416 2020-03-30 18:43:16+00:00  \n",
       "\n",
       "[6148105 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_special = test_data[[\"user_id\", \"replied_tweet_id\", \"tweet_creation_time\"]]\n",
    "convo_special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "    def __init__(self):\n",
    "        self.children = defaultdict(TrieNode)\n",
    "        self.is_end = False\n",
    "\n",
    "class Trie:\n",
    "    def __init__(self):\n",
    "        self.root = TrieNode()\n",
    "\n",
    "    def insert(self, conversation):\n",
    "        node = self.root\n",
    "        for tweet_id in conversation:\n",
    "            node = node.children[tweet_id]\n",
    "        node.is_end = True\n",
    "\n",
    "    def is_subset(self, conversation):\n",
    "        node = self.root\n",
    "        for tweet_id in conversation:\n",
    "            if tweet_id not in node.children:\n",
    "                return False\n",
    "            node = node.children[tweet_id]\n",
    "        return True\n",
    "\n",
    "def trace_conversation(start_tweet_id: str, tweet_dict: dict):\n",
    "    convo = []\n",
    "    current_tweet_id = start_tweet_id\n",
    "    users_in_conversation = set()\n",
    "    local_processed_tweet_ids = set()  # Local set to track the current conversation\n",
    "    while current_tweet_id:\n",
    "        if current_tweet_id not in tweet_dict or current_tweet_id in local_processed_tweet_ids:\n",
    "            break\n",
    "        tweet_info = tweet_dict[current_tweet_id]\n",
    "        convo.append(current_tweet_id)\n",
    "        users_in_conversation.add(tweet_info['user_id'])\n",
    "        local_processed_tweet_ids.add(current_tweet_id)\n",
    "        if len(users_in_conversation) > 2:\n",
    "            return convo[:-1][::-1]  # As soon as the third user appears, we delete his tweet and return\n",
    "        current_tweet_id = tweet_info['replied_tweet_id']\n",
    "    return convo[::-1] if len(users_in_conversation) == 2 else None\n",
    "\n",
    "def extract_and_filter_conversations(df: pd.DataFrame):\n",
    "    df = df.sort_values(\"tweet_creation_time\", ascending=False)\n",
    "    df.index = df.index.astype(str)\n",
    "    tweet_dict = df.to_dict('index')\n",
    "    conversations = []\n",
    "    trie = Trie()  # Initialize trie for subset checks\n",
    "\n",
    "    # Start tracing conversations from tweets that are replies\n",
    "    for tweet_id in tqdm(df[df['replied_tweet_id'].notnull()].index, desc=\"Extracting all conversations\"):\n",
    "        if conversation := trace_conversation(tweet_id, tweet_dict):\n",
    "            if not trie.is_subset(conversation):\n",
    "                trie.insert(conversation)\n",
    "                conversations.append(conversation)\n",
    "\n",
    "    return conversations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting all conversations: 100%|██████████| 1795409/1795409 [01:54<00:00, 15746.77it/s]\n"
     ]
    }
   ],
   "source": [
    "conversations = extract_and_filter_conversations(convo_special)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conversation</th>\n",
       "      <th>Tweet_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1244694453190897664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1244696682979303426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1244677304598609923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1244696641401163776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1244648694454026240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712242</th>\n",
       "      <td>1064150</td>\n",
       "      <td>451125255294443521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712243</th>\n",
       "      <td>1064151</td>\n",
       "      <td>430790355962052608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712244</th>\n",
       "      <td>1064151</td>\n",
       "      <td>430792524043931648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712245</th>\n",
       "      <td>1064152</td>\n",
       "      <td>248528541157834752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712246</th>\n",
       "      <td>1064152</td>\n",
       "      <td>248529937198366720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2712247 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Conversation             Tweet_ID\n",
       "0                   1  1244694453190897664\n",
       "1                   1  1244696682979303426\n",
       "2                   2  1244677304598609923\n",
       "3                   2  1244696641401163776\n",
       "4                   3  1244648694454026240\n",
       "...               ...                  ...\n",
       "2712242       1064150   451125255294443521\n",
       "2712243       1064151   430790355962052608\n",
       "2712244       1064151   430792524043931648\n",
       "2712245       1064152   248528541157834752\n",
       "2712246       1064152   248529937198366720\n",
       "\n",
       "[2712247 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for convo_num, convo in enumerate(conversations, start=1):\n",
    "    data.extend((convo_num, tweet_id) for tweet_id in convo)\n",
    "# Create a DataFrame\n",
    "df_conversations = pd.DataFrame(data, columns=['Conversation', 'Tweet_ID'])\n",
    "\n",
    "# Set MultiIndex\n",
    "df_conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_creation_time</th>\n",
       "      <th>tweet_creation_time</th>\n",
       "      <th>full_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>replied_tweet_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conversation</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>1244694453190897664</th>\n",
       "      <td>521835883</td>\n",
       "      <td>2012-03-12 01:11:22+00:00</td>\n",
       "      <td>2020-03-30 18:34:17+00:00</td>\n",
       "      <td>@nealrach @VirginAtlantic Siiiigh.... Still no...</td>\n",
       "      <td>en</td>\n",
       "      <td>1243885949697888263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244696682979303426</th>\n",
       "      <td>20626359</td>\n",
       "      <td>2009-02-11 20:50:56+00:00</td>\n",
       "      <td>2020-03-30 18:43:09+00:00</td>\n",
       "      <td>@Jade_Velveteese Hi Jade. We have an ‘Away fro...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244694453190897664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1244677304598609923</th>\n",
       "      <td>396021583</td>\n",
       "      <td>2011-10-22 16:35:05+00:00</td>\n",
       "      <td>2020-03-30 17:26:09+00:00</td>\n",
       "      <td>@VirginAtlantic Sod off your primary sharehold...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244669964289806338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244696641401163776</th>\n",
       "      <td>832964639436701696</td>\n",
       "      <td>2017-02-18 14:47:00+00:00</td>\n",
       "      <td>2020-03-30 18:42:59+00:00</td>\n",
       "      <td>@Boyde11 @VirginAtlantic Get your facts right,...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244677304598609923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>1244648694454026240</th>\n",
       "      <td>1233410199500791809</td>\n",
       "      <td>2020-02-28 15:14:56+00:00</td>\n",
       "      <td>2020-03-30 15:32:27+00:00</td>\n",
       "      <td>@flavioArCab @Chapux0204 @chechiffss @aeronaut...</td>\n",
       "      <td>es</td>\n",
       "      <td>1244643427515535360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064150</th>\n",
       "      <th>451125255294443521</th>\n",
       "      <td>22536055</td>\n",
       "      <td>2009-03-02 21:23:05+00:00</td>\n",
       "      <td>2014-04-01 22:33:37+00:00</td>\n",
       "      <td>@lanaupdates_ Your information has been forwar...</td>\n",
       "      <td>en</td>\n",
       "      <td>451124070730719233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1064151</th>\n",
       "      <th>430790355962052608</th>\n",
       "      <td>64327804</td>\n",
       "      <td>2009-08-10 03:34:27+00:00</td>\n",
       "      <td>2014-02-04 19:49:59+00:00</td>\n",
       "      <td>@AmericanAir phew, they finally turned on the ...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430792524043931648</th>\n",
       "      <td>22536055</td>\n",
       "      <td>2009-03-02 21:23:05+00:00</td>\n",
       "      <td>2014-02-04 19:58:36+00:00</td>\n",
       "      <td>@benjy_greenberg It looks like we'll have you ...</td>\n",
       "      <td>en</td>\n",
       "      <td>430790355962052608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1064152</th>\n",
       "      <th>248528541157834752</th>\n",
       "      <td>19911051</td>\n",
       "      <td>2009-02-02 15:17:02+00:00</td>\n",
       "      <td>2012-09-19 21:06:36+00:00</td>\n",
       "      <td>Un-fucking believable!\\nThanks @BritishAirways...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248529937198366720</th>\n",
       "      <td>399494759</td>\n",
       "      <td>2011-10-27 15:47:03+00:00</td>\n",
       "      <td>2012-09-19 21:12:09+00:00</td>\n",
       "      <td>@djmarkknight @britishairways i have have the ...</td>\n",
       "      <td>en</td>\n",
       "      <td>248528541157834752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2712247 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              user_id  \\\n",
       "Conversation Tweet_ID                                   \n",
       "1            1244694453190897664            521835883   \n",
       "             1244696682979303426             20626359   \n",
       "2            1244677304598609923            396021583   \n",
       "             1244696641401163776   832964639436701696   \n",
       "3            1244648694454026240  1233410199500791809   \n",
       "...                                               ...   \n",
       "1064150      451125255294443521              22536055   \n",
       "1064151      430790355962052608              64327804   \n",
       "             430792524043931648              22536055   \n",
       "1064152      248528541157834752              19911051   \n",
       "             248529937198366720             399494759   \n",
       "\n",
       "                                        user_creation_time  \\\n",
       "Conversation Tweet_ID                                        \n",
       "1            1244694453190897664 2012-03-12 01:11:22+00:00   \n",
       "             1244696682979303426 2009-02-11 20:50:56+00:00   \n",
       "2            1244677304598609923 2011-10-22 16:35:05+00:00   \n",
       "             1244696641401163776 2017-02-18 14:47:00+00:00   \n",
       "3            1244648694454026240 2020-02-28 15:14:56+00:00   \n",
       "...                                                    ...   \n",
       "1064150      451125255294443521  2009-03-02 21:23:05+00:00   \n",
       "1064151      430790355962052608  2009-08-10 03:34:27+00:00   \n",
       "             430792524043931648  2009-03-02 21:23:05+00:00   \n",
       "1064152      248528541157834752  2009-02-02 15:17:02+00:00   \n",
       "             248529937198366720  2011-10-27 15:47:03+00:00   \n",
       "\n",
       "                                       tweet_creation_time  \\\n",
       "Conversation Tweet_ID                                        \n",
       "1            1244694453190897664 2020-03-30 18:34:17+00:00   \n",
       "             1244696682979303426 2020-03-30 18:43:09+00:00   \n",
       "2            1244677304598609923 2020-03-30 17:26:09+00:00   \n",
       "             1244696641401163776 2020-03-30 18:42:59+00:00   \n",
       "3            1244648694454026240 2020-03-30 15:32:27+00:00   \n",
       "...                                                    ...   \n",
       "1064150      451125255294443521  2014-04-01 22:33:37+00:00   \n",
       "1064151      430790355962052608  2014-02-04 19:49:59+00:00   \n",
       "             430792524043931648  2014-02-04 19:58:36+00:00   \n",
       "1064152      248528541157834752  2012-09-19 21:06:36+00:00   \n",
       "             248529937198366720  2012-09-19 21:12:09+00:00   \n",
       "\n",
       "                                                                          full_text  \\\n",
       "Conversation Tweet_ID                                                                 \n",
       "1            1244694453190897664  @nealrach @VirginAtlantic Siiiigh.... Still no...   \n",
       "             1244696682979303426  @Jade_Velveteese Hi Jade. We have an ‘Away fro...   \n",
       "2            1244677304598609923  @VirginAtlantic Sod off your primary sharehold...   \n",
       "             1244696641401163776  @Boyde11 @VirginAtlantic Get your facts right,...   \n",
       "3            1244648694454026240  @flavioArCab @Chapux0204 @chechiffss @aeronaut...   \n",
       "...                                                                             ...   \n",
       "1064150      451125255294443521   @lanaupdates_ Your information has been forwar...   \n",
       "1064151      430790355962052608   @AmericanAir phew, they finally turned on the ...   \n",
       "             430792524043931648   @benjy_greenberg It looks like we'll have you ...   \n",
       "1064152      248528541157834752   Un-fucking believable!\\nThanks @BritishAirways...   \n",
       "             248529937198366720   @djmarkknight @britishairways i have have the ...   \n",
       "\n",
       "                                 lang     replied_tweet_id  \n",
       "Conversation Tweet_ID                                       \n",
       "1            1244694453190897664   en  1243885949697888263  \n",
       "             1244696682979303426   en  1244694453190897664  \n",
       "2            1244677304598609923   en  1244669964289806338  \n",
       "             1244696641401163776   en  1244677304598609923  \n",
       "3            1244648694454026240   es  1244643427515535360  \n",
       "...                               ...                  ...  \n",
       "1064150      451125255294443521    en   451124070730719233  \n",
       "1064151      430790355962052608    en                 None  \n",
       "             430792524043931648    en   430790355962052608  \n",
       "1064152      248528541157834752    en                 None  \n",
       "             248529937198366720    en   248528541157834752  \n",
       "\n",
       "[2712247 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Merge the conversation DataFrame with the test_data DataFrame\n",
    "df_conversations_full = df_conversations.merge(test_data, left_on='Tweet_ID', right_index=True, how='left')\n",
    "\n",
    "# Set the MultiIndex again with Conversation and Tweet_ID\n",
    "df_conversations_full.set_index(['Conversation', 'Tweet_ID'], inplace=True)\n",
    "df_conversations_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_creation_time</th>\n",
       "      <th>tweet_creation_time</th>\n",
       "      <th>full_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>replied_tweet_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conversation</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">140</th>\n",
       "      <th>1244658051740774400</th>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-30 16:09:38+00:00</td>\n",
       "      <td>@thick_daddy The online cancellation tool will...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244650317494566913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244688840033546245</th>\n",
       "      <td>119901222</td>\n",
       "      <td>2010-03-04 22:18:43+00:00</td>\n",
       "      <td>2020-03-30 18:11:59+00:00</td>\n",
       "      <td>@lufthansa @thick_daddy I received the same em...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244658051740774400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244691330837762051</th>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-30 18:21:53+00:00</td>\n",
       "      <td>@NateThomasNOLA @thick_daddy At the moment, my...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244688840033546245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">194</th>\n",
       "      <th>1244684192040071173</th>\n",
       "      <td>62555545</td>\n",
       "      <td>2009-08-03 16:35:21+00:00</td>\n",
       "      <td>2020-03-30 17:53:31+00:00</td>\n",
       "      <td>@lufthansa had an email stating changes to my ...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244688444162486273</th>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-30 18:10:24+00:00</td>\n",
       "      <td>@Holgate1987 At the moment, my colleagues in t...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244684192040071173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064013</th>\n",
       "      <th>1095473044573700096</th>\n",
       "      <td>1339792290</td>\n",
       "      <td>2013-04-09 17:56:30+00:00</td>\n",
       "      <td>2019-02-13 00:01:41+00:00</td>\n",
       "      <td>@lufthansa Read on @YahooNews you sued a guy f...</td>\n",
       "      <td>en</td>\n",
       "      <td>1094985662384594944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1064019</th>\n",
       "      <th>1090912573304774662</th>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2019-01-31 10:00:00+00:00</td>\n",
       "      <td>With 297 seats, the #A340-600 is next in line ...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090913775417479168</th>\n",
       "      <td>18631142</td>\n",
       "      <td>2009-01-05 13:13:10+00:00</td>\n",
       "      <td>2019-01-31 10:04:46+00:00</td>\n",
       "      <td>@lufthansa 747-400, then 747-8, then A380. :)</td>\n",
       "      <td>en</td>\n",
       "      <td>1090912573304774662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1064028</th>\n",
       "      <th>1083376699780280321</th>\n",
       "      <td>478699784</td>\n",
       "      <td>2012-01-30 15:32:40+00:00</td>\n",
       "      <td>2019-01-10 14:55:08+00:00</td>\n",
       "      <td>Hi @lufthansa how come there is no 'Ms' option...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083381532071469058</th>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2019-01-10 15:14:20+00:00</td>\n",
       "      <td>@JosephPKilroy The \"Ms\" option is supposed to ...</td>\n",
       "      <td>en</td>\n",
       "      <td>1083376699780280321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44091 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     user_id        user_creation_time  \\\n",
       "Conversation Tweet_ID                                                    \n",
       "140          1244658051740774400   124476322 2010-03-19 14:30:32+00:00   \n",
       "             1244688840033546245   119901222 2010-03-04 22:18:43+00:00   \n",
       "             1244691330837762051   124476322 2010-03-19 14:30:32+00:00   \n",
       "194          1244684192040071173    62555545 2009-08-03 16:35:21+00:00   \n",
       "             1244688444162486273   124476322 2010-03-19 14:30:32+00:00   \n",
       "...                                      ...                       ...   \n",
       "1064013      1095473044573700096  1339792290 2013-04-09 17:56:30+00:00   \n",
       "1064019      1090912573304774662   124476322 2010-03-19 14:30:32+00:00   \n",
       "             1090913775417479168    18631142 2009-01-05 13:13:10+00:00   \n",
       "1064028      1083376699780280321   478699784 2012-01-30 15:32:40+00:00   \n",
       "             1083381532071469058   124476322 2010-03-19 14:30:32+00:00   \n",
       "\n",
       "                                       tweet_creation_time  \\\n",
       "Conversation Tweet_ID                                        \n",
       "140          1244658051740774400 2020-03-30 16:09:38+00:00   \n",
       "             1244688840033546245 2020-03-30 18:11:59+00:00   \n",
       "             1244691330837762051 2020-03-30 18:21:53+00:00   \n",
       "194          1244684192040071173 2020-03-30 17:53:31+00:00   \n",
       "             1244688444162486273 2020-03-30 18:10:24+00:00   \n",
       "...                                                    ...   \n",
       "1064013      1095473044573700096 2019-02-13 00:01:41+00:00   \n",
       "1064019      1090912573304774662 2019-01-31 10:00:00+00:00   \n",
       "             1090913775417479168 2019-01-31 10:04:46+00:00   \n",
       "1064028      1083376699780280321 2019-01-10 14:55:08+00:00   \n",
       "             1083381532071469058 2019-01-10 15:14:20+00:00   \n",
       "\n",
       "                                                                          full_text  \\\n",
       "Conversation Tweet_ID                                                                 \n",
       "140          1244658051740774400  @thick_daddy The online cancellation tool will...   \n",
       "             1244688840033546245  @lufthansa @thick_daddy I received the same em...   \n",
       "             1244691330837762051  @NateThomasNOLA @thick_daddy At the moment, my...   \n",
       "194          1244684192040071173  @lufthansa had an email stating changes to my ...   \n",
       "             1244688444162486273  @Holgate1987 At the moment, my colleagues in t...   \n",
       "...                                                                             ...   \n",
       "1064013      1095473044573700096  @lufthansa Read on @YahooNews you sued a guy f...   \n",
       "1064019      1090912573304774662  With 297 seats, the #A340-600 is next in line ...   \n",
       "             1090913775417479168      @lufthansa 747-400, then 747-8, then A380. :)   \n",
       "1064028      1083376699780280321  Hi @lufthansa how come there is no 'Ms' option...   \n",
       "             1083381532071469058  @JosephPKilroy The \"Ms\" option is supposed to ...   \n",
       "\n",
       "                                 lang     replied_tweet_id  \n",
       "Conversation Tweet_ID                                       \n",
       "140          1244658051740774400   en  1244650317494566913  \n",
       "             1244688840033546245   en  1244658051740774400  \n",
       "             1244691330837762051   en  1244688840033546245  \n",
       "194          1244684192040071173   en                 None  \n",
       "             1244688444162486273   en  1244684192040071173  \n",
       "...                               ...                  ...  \n",
       "1064013      1095473044573700096   en  1094985662384594944  \n",
       "1064019      1090912573304774662   en                 None  \n",
       "             1090913775417479168   en  1090912573304774662  \n",
       "1064028      1083376699780280321   en                 None  \n",
       "             1083381532071469058   en  1083376699780280321  \n",
       "\n",
       "[44091 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_conversation = df_conversations_full.loc[df_conversations_full.index.get_level_values('Conversation').isin(df_conversations_full[df_conversations_full['user_id'] == COMPANY_NAME_TO_ID[\"Lufthansa\"]].index.get_level_values('Conversation'))]\n",
    "airline_conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Conversation</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_creation_time</th>\n",
       "      <th>tweet_creation_time</th>\n",
       "      <th>full_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>replied_tweet_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New_Conversation</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>1244658051740774400</th>\n",
       "      <td>140</td>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-30 16:09:38+00:00</td>\n",
       "      <td>@thick_daddy The online cancellation tool will...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244650317494566913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244688840033546245</th>\n",
       "      <td>140</td>\n",
       "      <td>119901222</td>\n",
       "      <td>2010-03-04 22:18:43+00:00</td>\n",
       "      <td>2020-03-30 18:11:59+00:00</td>\n",
       "      <td>@lufthansa @thick_daddy I received the same em...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244658051740774400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244691330837762051</th>\n",
       "      <td>140</td>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-30 18:21:53+00:00</td>\n",
       "      <td>@NateThomasNOLA @thick_daddy At the moment, my...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244688840033546245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1244684192040071173</th>\n",
       "      <td>194</td>\n",
       "      <td>62555545</td>\n",
       "      <td>2009-08-03 16:35:21+00:00</td>\n",
       "      <td>2020-03-30 17:53:31+00:00</td>\n",
       "      <td>@lufthansa had an email stating changes to my ...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244688444162486273</th>\n",
       "      <td>194</td>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-30 18:10:24+00:00</td>\n",
       "      <td>@Holgate1987 At the moment, my colleagues in t...</td>\n",
       "      <td>en</td>\n",
       "      <td>1244684192040071173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14271</th>\n",
       "      <th>1095473044573700096</th>\n",
       "      <td>1064013</td>\n",
       "      <td>1339792290</td>\n",
       "      <td>2013-04-09 17:56:30+00:00</td>\n",
       "      <td>2019-02-13 00:01:41+00:00</td>\n",
       "      <td>@lufthansa Read on @YahooNews you sued a guy f...</td>\n",
       "      <td>en</td>\n",
       "      <td>1094985662384594944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">14272</th>\n",
       "      <th>1090912573304774662</th>\n",
       "      <td>1064019</td>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2019-01-31 10:00:00+00:00</td>\n",
       "      <td>With 297 seats, the #A340-600 is next in line ...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090913775417479168</th>\n",
       "      <td>1064019</td>\n",
       "      <td>18631142</td>\n",
       "      <td>2009-01-05 13:13:10+00:00</td>\n",
       "      <td>2019-01-31 10:04:46+00:00</td>\n",
       "      <td>@lufthansa 747-400, then 747-8, then A380. :)</td>\n",
       "      <td>en</td>\n",
       "      <td>1090912573304774662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">14273</th>\n",
       "      <th>1083376699780280321</th>\n",
       "      <td>1064028</td>\n",
       "      <td>478699784</td>\n",
       "      <td>2012-01-30 15:32:40+00:00</td>\n",
       "      <td>2019-01-10 14:55:08+00:00</td>\n",
       "      <td>Hi @lufthansa how come there is no 'Ms' option...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083381532071469058</th>\n",
       "      <td>1064028</td>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2019-01-10 15:14:20+00:00</td>\n",
       "      <td>@JosephPKilroy The \"Ms\" option is supposed to ...</td>\n",
       "      <td>en</td>\n",
       "      <td>1083376699780280321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44091 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Conversation     user_id  \\\n",
       "New_Conversation Tweet_ID                                        \n",
       "1                1244658051740774400           140   124476322   \n",
       "                 1244688840033546245           140   119901222   \n",
       "                 1244691330837762051           140   124476322   \n",
       "2                1244684192040071173           194    62555545   \n",
       "                 1244688444162486273           194   124476322   \n",
       "...                                            ...         ...   \n",
       "14271            1095473044573700096       1064013  1339792290   \n",
       "14272            1090912573304774662       1064019   124476322   \n",
       "                 1090913775417479168       1064019    18631142   \n",
       "14273            1083376699780280321       1064028   478699784   \n",
       "                 1083381532071469058       1064028   124476322   \n",
       "\n",
       "                                            user_creation_time  \\\n",
       "New_Conversation Tweet_ID                                        \n",
       "1                1244658051740774400 2010-03-19 14:30:32+00:00   \n",
       "                 1244688840033546245 2010-03-04 22:18:43+00:00   \n",
       "                 1244691330837762051 2010-03-19 14:30:32+00:00   \n",
       "2                1244684192040071173 2009-08-03 16:35:21+00:00   \n",
       "                 1244688444162486273 2010-03-19 14:30:32+00:00   \n",
       "...                                                        ...   \n",
       "14271            1095473044573700096 2013-04-09 17:56:30+00:00   \n",
       "14272            1090912573304774662 2010-03-19 14:30:32+00:00   \n",
       "                 1090913775417479168 2009-01-05 13:13:10+00:00   \n",
       "14273            1083376699780280321 2012-01-30 15:32:40+00:00   \n",
       "                 1083381532071469058 2010-03-19 14:30:32+00:00   \n",
       "\n",
       "                                           tweet_creation_time  \\\n",
       "New_Conversation Tweet_ID                                        \n",
       "1                1244658051740774400 2020-03-30 16:09:38+00:00   \n",
       "                 1244688840033546245 2020-03-30 18:11:59+00:00   \n",
       "                 1244691330837762051 2020-03-30 18:21:53+00:00   \n",
       "2                1244684192040071173 2020-03-30 17:53:31+00:00   \n",
       "                 1244688444162486273 2020-03-30 18:10:24+00:00   \n",
       "...                                                        ...   \n",
       "14271            1095473044573700096 2019-02-13 00:01:41+00:00   \n",
       "14272            1090912573304774662 2019-01-31 10:00:00+00:00   \n",
       "                 1090913775417479168 2019-01-31 10:04:46+00:00   \n",
       "14273            1083376699780280321 2019-01-10 14:55:08+00:00   \n",
       "                 1083381532071469058 2019-01-10 15:14:20+00:00   \n",
       "\n",
       "                                                                              full_text  \\\n",
       "New_Conversation Tweet_ID                                                                 \n",
       "1                1244658051740774400  @thick_daddy The online cancellation tool will...   \n",
       "                 1244688840033546245  @lufthansa @thick_daddy I received the same em...   \n",
       "                 1244691330837762051  @NateThomasNOLA @thick_daddy At the moment, my...   \n",
       "2                1244684192040071173  @lufthansa had an email stating changes to my ...   \n",
       "                 1244688444162486273  @Holgate1987 At the moment, my colleagues in t...   \n",
       "...                                                                                 ...   \n",
       "14271            1095473044573700096  @lufthansa Read on @YahooNews you sued a guy f...   \n",
       "14272            1090912573304774662  With 297 seats, the #A340-600 is next in line ...   \n",
       "                 1090913775417479168      @lufthansa 747-400, then 747-8, then A380. :)   \n",
       "14273            1083376699780280321  Hi @lufthansa how come there is no 'Ms' option...   \n",
       "                 1083381532071469058  @JosephPKilroy The \"Ms\" option is supposed to ...   \n",
       "\n",
       "                                     lang     replied_tweet_id  \n",
       "New_Conversation Tweet_ID                                       \n",
       "1                1244658051740774400   en  1244650317494566913  \n",
       "                 1244688840033546245   en  1244658051740774400  \n",
       "                 1244691330837762051   en  1244688840033546245  \n",
       "2                1244684192040071173   en                 None  \n",
       "                 1244688444162486273   en  1244684192040071173  \n",
       "...                                   ...                  ...  \n",
       "14271            1095473044573700096   en  1094985662384594944  \n",
       "14272            1090912573304774662   en                 None  \n",
       "                 1090913775417479168   en  1090912573304774662  \n",
       "14273            1083376699780280321   en                 None  \n",
       "                 1083381532071469058   en  1083376699780280321  \n",
       "\n",
       "[44091 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline_conversation = airline_conversation.reset_index()\n",
    "airline_conversation['New_Conversation'] = pd.factorize(airline_conversation['Conversation'])[0] + 1\n",
    "airline_conversation = airline_conversation.set_index(['New_Conversation', 'Tweet_ID'])\n",
    "airline_conversation = airline_conversation.sort_index(level='New_Conversation')\n",
    "airline_conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFXLMRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFXLMRobertaForSequenceClassification were initialized from the model checkpoint at joeddav/xlm-roberta-large-xnli.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'New_Conversation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/new_fucking_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'New_Conversation'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m first_tweet_texts \u001b[38;5;241m=\u001b[39m conversation_groups\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m group: group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     31\u001b[0m categories \u001b[38;5;241m=\u001b[39m first_tweet_texts\u001b[38;5;241m.\u001b[39mapply(classify_conversation)\n\u001b[0;32m---> 32\u001b[0m test_airline_conversation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_airline_conversation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew_Conversation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(categories)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_fucking_env/lib/python3.11/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/new_fucking_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'New_Conversation'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "test_airline_conversation = airline_conversation.head(10)\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"joeddav/xlm-roberta-large-xnli\")\n",
    "\n",
    "candidate_labels = [\n",
    "    \"Flight Delays / Cancellations\",\n",
    "    \"Booking\",\n",
    "    \"Check-in\",\n",
    "    \"Customer Service Complaints\",\n",
    "    \"Seating / Boarding\",\n",
    "    \"In-flight Experience\",\n",
    "    \"General Flight Information\",\n",
    "    \"Refunds\",\n",
    "    \"Frequent Flyer Program\",\n",
    "    \"Safety / Security\",\n",
    "    \"Special Assistance\",\n",
    "    \"Food / Beverage\",\n",
    "    \"Overbooking\",\n",
    "    \"Technical Difficulties\",\n",
    "    \"Promotions / Offers\",\n",
    "    \"Lost Luggage\",\n",
    "    \"Baggage Issues\"\n",
    "]\n",
    "def classify_conversation(conversation_text):\n",
    "    result = classifier(conversation_text, candidate_labels)\n",
    "    return result['labels'][0]\n",
    "\n",
    "conversation_groups = test_airline_conversation.groupby('New_Conversation')\n",
    "first_tweet_texts = conversation_groups.apply(lambda group: group['full_text'].iloc[0])\n",
    "categories = first_tweet_texts.apply(classify_conversation)\n",
    "test_airline_conversation['category'] = test_airline_conversation['New_Conversation'].map(categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Conversation</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_creation_time</th>\n",
       "      <th>tweet_creation_time</th>\n",
       "      <th>full_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>replied_tweet_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New_Conversation</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>1244658051740774400</th>\n",
       "      <td>140</td>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-30 16:09:38+00:00</td>\n",
       "      <td>@thick_daddy The online cancellation tool will only refund according to the fare conditions, Penelope. /Mac</td>\n",
       "      <td>en</td>\n",
       "      <td>1244650317494566913</td>\n",
       "      <td>cancellations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244688840033546245</th>\n",
       "      <td>140</td>\n",
       "      <td>119901222</td>\n",
       "      <td>2010-03-04 22:18:43+00:00</td>\n",
       "      <td>2020-03-30 18:11:59+00:00</td>\n",
       "      <td>@lufthansa @thick_daddy I received the same email after cancelling and requesting a refund online (my flight segments had been cancelled by airline).  Are you able to check refund status, or do we have to call the service center?</td>\n",
       "      <td>en</td>\n",
       "      <td>1244658051740774400</td>\n",
       "      <td>cancellations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244691330837762051</th>\n",
       "      <td>140</td>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-30 18:21:53+00:00</td>\n",
       "      <td>@NateThomasNOLA @thick_daddy At the moment, my colleagues in the Service Center are working on all re-bookings for the next 72 hours. Please reach out to them at a later stage to inquire about your refund status https://t.co/eRWyrKTFGQ. /Susi</td>\n",
       "      <td>en</td>\n",
       "      <td>1244688840033546245</td>\n",
       "      <td>cancellations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>1244684192040071173</th>\n",
       "      <td>194</td>\n",
       "      <td>62555545</td>\n",
       "      <td>2009-08-03 16:35:21+00:00</td>\n",
       "      <td>2020-03-30 17:53:31+00:00</td>\n",
       "      <td>@lufthansa had an email stating changes to my reservation ( you have cancelled my last leg and leaves me stranded in frankfurt ) states about rearranging via phone, but how can I when can't get through, no mention of refund tho, however you've cancelled so im entitled !! Advise</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>booking issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244688444162486273</th>\n",
       "      <td>194</td>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-30 18:10:24+00:00</td>\n",
       "      <td>@Holgate1987 At the moment, my colleagues in the Service Center are working on all re-bookings for the next 72 hours. Please reach out to them at a later stage to request a refund https://t.co/eRWyrKTFGQ. /Susi</td>\n",
       "      <td>en</td>\n",
       "      <td>1244684192040071173</td>\n",
       "      <td>booking issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244689066567794688</th>\n",
       "      <td>194</td>\n",
       "      <td>62555545</td>\n",
       "      <td>2009-08-03 16:35:21+00:00</td>\n",
       "      <td>2020-03-30 18:12:53+00:00</td>\n",
       "      <td>@lufthansa My fight is in 3 days !!! last time I spoke to a rep 3 weeks ago, they said they would refund me in full, I got an email stating this would happen and nothing, why was I lied to ? They're rebooking for next 72hours so if I call in 4 days I will get a refund ?</td>\n",
       "      <td>en</td>\n",
       "      <td>1244688444162486273</td>\n",
       "      <td>booking issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>1244685953983225857</th>\n",
       "      <td>195</td>\n",
       "      <td>562252389</td>\n",
       "      <td>2012-04-24 16:49:01+00:00</td>\n",
       "      <td>2020-03-30 18:00:31+00:00</td>\n",
       "      <td>@lufthansa I requested a refund back on 16/03 and I’m yet to receive any updates. I appreciate your busy I’ve tried calling numerous times for 2hrs plus. Could you give me an update?</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>refunds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244689043952209921</th>\n",
       "      <td>195</td>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-30 18:12:47+00:00</td>\n",
       "      <td>@AndyHall52 Due to the sheer amount of refund requests needed to be initiated manually by my colleagues, we are unable to predict you with a time frame at the moment, unfortunately. Your patience is highly appreciated, as my colleagues will refund your ticket as soon as possible. /Susi</td>\n",
       "      <td>en</td>\n",
       "      <td>1244685953983225857</td>\n",
       "      <td>refunds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4</th>\n",
       "      <th>1244684192040071173</th>\n",
       "      <td>201</td>\n",
       "      <td>62555545</td>\n",
       "      <td>2009-08-03 16:35:21+00:00</td>\n",
       "      <td>2020-03-30 17:53:31+00:00</td>\n",
       "      <td>@lufthansa had an email stating changes to my reservation ( you have cancelled my last leg and leaves me stranded in frankfurt ) states about rearranging via phone, but how can I when can't get through, no mention of refund tho, however you've cancelled so im entitled !! Advise</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>booking issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244688444162486273</th>\n",
       "      <td>201</td>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-30 18:10:24+00:00</td>\n",
       "      <td>@Holgate1987 At the moment, my colleagues in the Service Center are working on all re-bookings for the next 72 hours. Please reach out to them at a later stage to request a refund https://t.co/eRWyrKTFGQ. /Susi</td>\n",
       "      <td>en</td>\n",
       "      <td>1244684192040071173</td>\n",
       "      <td>booking issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244688904957165571</th>\n",
       "      <td>201</td>\n",
       "      <td>62555545</td>\n",
       "      <td>2009-08-03 16:35:21+00:00</td>\n",
       "      <td>2020-03-30 18:12:14+00:00</td>\n",
       "      <td>@lufthansa My fight is in 3 days !!! last time I spoke to a rep 3 weeks ago, they said they would refund me in full, I got an email stating this would happen and nothing, why was I lied to ? They're revoking for next 72hours so if I call in 4 days I will get a refund ?</td>\n",
       "      <td>en</td>\n",
       "      <td>1244688444162486273</td>\n",
       "      <td>booking issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>1244683083623870466</th>\n",
       "      <td>232</td>\n",
       "      <td>1227452210239418368</td>\n",
       "      <td>2020-02-12 04:39:54+00:00</td>\n",
       "      <td>2020-03-30 17:49:06+00:00</td>\n",
       "      <td>@lufthansa Hi, when can I expect a refund for a booking of mine, which you cancelled? I have been waiting for 2 weeks now.\\n\\nI have attempted to contact you via Phone and Email, but to no success.</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>booking issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244687406735011841</th>\n",
       "      <td>232</td>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-30 18:06:17+00:00</td>\n",
       "      <td>@__01Alex Due to the sheer amount of refund requests needed to be initiated manually by my colleagues, we are unable to predict you with a time frame at the moment, unfortunately. Your patience is highly appreciated, as my colleagues will refund your ticket as soon as possible. /Susi</td>\n",
       "      <td>en</td>\n",
       "      <td>1244683083623870466</td>\n",
       "      <td>booking issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>1242802417466576897</th>\n",
       "      <td>238</td>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-25 13:16:01+00:00</td>\n",
       "      <td>We were already able to bring 17,000 passengers back home, we are flying important humanitarian goods to wherever they are needed most, and we are taking care of your bookings. Thank you for your patience. Further information: https://t.co/Ne1bKLJj0A https://t.co/L39QksjCQB</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>booking issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244687164467744773</th>\n",
       "      <td>238</td>\n",
       "      <td>1044584719193526272</td>\n",
       "      <td>2018-09-25 13:49:39+00:00</td>\n",
       "      <td>2020-03-30 18:05:19+00:00</td>\n",
       "      <td>@lufthansa Stop lying! Get bankrupt already. Otherwise I don’t see a reason why you steal people’s money! #Coronavirustruth #Covid_19 #theves #scamairline #scam #ScamAware #SCAM #fuckthisairline #whereismymoney</td>\n",
       "      <td>en</td>\n",
       "      <td>1242802417466576897</td>\n",
       "      <td>booking issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>1243168721843216384</th>\n",
       "      <td>249</td>\n",
       "      <td>124476322</td>\n",
       "      <td>2010-03-19 14:30:32+00:00</td>\n",
       "      <td>2020-03-26 13:31:34+00:00</td>\n",
       "      <td>Physical distancing: Lufthansa introduces further distance rules. From tomorrow on all flights from Germany the neighbouring seats remain free. Arrivals &amp;amp; departures in Germany only at gate positions to avoid bus shuttles. https://t.co/YtyRngk6n7 https://t.co/TpiPlSLXvi</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>refunds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244686742420144130</th>\n",
       "      <td>249</td>\n",
       "      <td>1044584719193526272</td>\n",
       "      <td>2018-09-25 13:49:39+00:00</td>\n",
       "      <td>2020-03-30 18:03:39+00:00</td>\n",
       "      <td>@lufthansa Before you make changes! Refund the money you owe to passengers you screwed over #fuckthisairline #scam #COVID19 #coronavirus #FAILED #fail20 #shitairline #theves</td>\n",
       "      <td>en</td>\n",
       "      <td>1243168721843216384</td>\n",
       "      <td>refunds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">8</th>\n",
       "      <th>1244635094486138880</th>\n",
       "      <td>252</td>\n",
       "      <td>947273605259206656</td>\n",
       "      <td>2017-12-31 01:10:01+00:00</td>\n",
       "      <td>2020-03-30 14:38:25+00:00</td>\n",
       "      <td>@lufthansa  I booked my dream holiday to Rome (Italy) in January'2020 as a good passenger by making full payment before CARONA pandamic. After the outbreak happened, Indian government cancelled all international travel especially to Italy.</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>cancellations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244635963051008002</th>\n",
       "      <td>252</td>\n",
       "      <td>947273605259206656</td>\n",
       "      <td>2017-12-31 01:10:01+00:00</td>\n",
       "      <td>2020-03-30 14:41:52+00:00</td>\n",
       "      <td>Then like a good citizen of india i cancelled my ticket on https://t.co/QUAssBVj5T the meantime @lufthansa changed my schedule without my knowledge and now they have changed policy of not giving refund of my ticket but credit. Please behave sensibly and give me full refund.</td>\n",
       "      <td>en</td>\n",
       "      <td>1244635094486138880</td>\n",
       "      <td>cancellations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244636899827806211</th>\n",
       "      <td>252</td>\n",
       "      <td>947273605259206656</td>\n",
       "      <td>2017-12-31 01:10:01+00:00</td>\n",
       "      <td>2020-03-30 14:45:35+00:00</td>\n",
       "      <td>@lufthansa @Lufthansa_USA @lufthansaNews \\nI booked my tickets with you thinking that I can rest assured as @lufthansa is reputed company and never thought they will change their rules overnight. So request you to please help me in getting my full refund.</td>\n",
       "      <td>en</td>\n",
       "      <td>1244635963051008002</td>\n",
       "      <td>cancellations</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Conversation              user_id  \\\n",
       "New_Conversation Tweet_ID                                                 \n",
       "1                1244658051740774400           140            124476322   \n",
       "                 1244688840033546245           140            119901222   \n",
       "                 1244691330837762051           140            124476322   \n",
       "2                1244684192040071173           194             62555545   \n",
       "                 1244688444162486273           194            124476322   \n",
       "                 1244689066567794688           194             62555545   \n",
       "3                1244685953983225857           195            562252389   \n",
       "                 1244689043952209921           195            124476322   \n",
       "4                1244684192040071173           201             62555545   \n",
       "                 1244688444162486273           201            124476322   \n",
       "                 1244688904957165571           201             62555545   \n",
       "5                1244683083623870466           232  1227452210239418368   \n",
       "                 1244687406735011841           232            124476322   \n",
       "6                1242802417466576897           238            124476322   \n",
       "                 1244687164467744773           238  1044584719193526272   \n",
       "7                1243168721843216384           249            124476322   \n",
       "                 1244686742420144130           249  1044584719193526272   \n",
       "8                1244635094486138880           252   947273605259206656   \n",
       "                 1244635963051008002           252   947273605259206656   \n",
       "                 1244636899827806211           252   947273605259206656   \n",
       "\n",
       "                                            user_creation_time  \\\n",
       "New_Conversation Tweet_ID                                        \n",
       "1                1244658051740774400 2010-03-19 14:30:32+00:00   \n",
       "                 1244688840033546245 2010-03-04 22:18:43+00:00   \n",
       "                 1244691330837762051 2010-03-19 14:30:32+00:00   \n",
       "2                1244684192040071173 2009-08-03 16:35:21+00:00   \n",
       "                 1244688444162486273 2010-03-19 14:30:32+00:00   \n",
       "                 1244689066567794688 2009-08-03 16:35:21+00:00   \n",
       "3                1244685953983225857 2012-04-24 16:49:01+00:00   \n",
       "                 1244689043952209921 2010-03-19 14:30:32+00:00   \n",
       "4                1244684192040071173 2009-08-03 16:35:21+00:00   \n",
       "                 1244688444162486273 2010-03-19 14:30:32+00:00   \n",
       "                 1244688904957165571 2009-08-03 16:35:21+00:00   \n",
       "5                1244683083623870466 2020-02-12 04:39:54+00:00   \n",
       "                 1244687406735011841 2010-03-19 14:30:32+00:00   \n",
       "6                1242802417466576897 2010-03-19 14:30:32+00:00   \n",
       "                 1244687164467744773 2018-09-25 13:49:39+00:00   \n",
       "7                1243168721843216384 2010-03-19 14:30:32+00:00   \n",
       "                 1244686742420144130 2018-09-25 13:49:39+00:00   \n",
       "8                1244635094486138880 2017-12-31 01:10:01+00:00   \n",
       "                 1244635963051008002 2017-12-31 01:10:01+00:00   \n",
       "                 1244636899827806211 2017-12-31 01:10:01+00:00   \n",
       "\n",
       "                                           tweet_creation_time  \\\n",
       "New_Conversation Tweet_ID                                        \n",
       "1                1244658051740774400 2020-03-30 16:09:38+00:00   \n",
       "                 1244688840033546245 2020-03-30 18:11:59+00:00   \n",
       "                 1244691330837762051 2020-03-30 18:21:53+00:00   \n",
       "2                1244684192040071173 2020-03-30 17:53:31+00:00   \n",
       "                 1244688444162486273 2020-03-30 18:10:24+00:00   \n",
       "                 1244689066567794688 2020-03-30 18:12:53+00:00   \n",
       "3                1244685953983225857 2020-03-30 18:00:31+00:00   \n",
       "                 1244689043952209921 2020-03-30 18:12:47+00:00   \n",
       "4                1244684192040071173 2020-03-30 17:53:31+00:00   \n",
       "                 1244688444162486273 2020-03-30 18:10:24+00:00   \n",
       "                 1244688904957165571 2020-03-30 18:12:14+00:00   \n",
       "5                1244683083623870466 2020-03-30 17:49:06+00:00   \n",
       "                 1244687406735011841 2020-03-30 18:06:17+00:00   \n",
       "6                1242802417466576897 2020-03-25 13:16:01+00:00   \n",
       "                 1244687164467744773 2020-03-30 18:05:19+00:00   \n",
       "7                1243168721843216384 2020-03-26 13:31:34+00:00   \n",
       "                 1244686742420144130 2020-03-30 18:03:39+00:00   \n",
       "8                1244635094486138880 2020-03-30 14:38:25+00:00   \n",
       "                 1244635963051008002 2020-03-30 14:41:52+00:00   \n",
       "                 1244636899827806211 2020-03-30 14:45:35+00:00   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                           full_text  \\\n",
       "New_Conversation Tweet_ID                                                                                                                                                                                                                                                                                                              \n",
       "1                1244658051740774400                                                                                                                                                                                     @thick_daddy The online cancellation tool will only refund according to the fare conditions, Penelope. /Mac   \n",
       "                 1244688840033546245                                                           @lufthansa @thick_daddy I received the same email after cancelling and requesting a refund online (my flight segments had been cancelled by airline).  Are you able to check refund status, or do we have to call the service center?   \n",
       "                 1244691330837762051                                              @NateThomasNOLA @thick_daddy At the moment, my colleagues in the Service Center are working on all re-bookings for the next 72 hours. Please reach out to them at a later stage to inquire about your refund status https://t.co/eRWyrKTFGQ. /Susi   \n",
       "2                1244684192040071173          @lufthansa had an email stating changes to my reservation ( you have cancelled my last leg and leaves me stranded in frankfurt ) states about rearranging via phone, but how can I when can't get through, no mention of refund tho, however you've cancelled so im entitled !! Advise   \n",
       "                 1244688444162486273                                                                              @Holgate1987 At the moment, my colleagues in the Service Center are working on all re-bookings for the next 72 hours. Please reach out to them at a later stage to request a refund https://t.co/eRWyrKTFGQ. /Susi   \n",
       "                 1244689066567794688                  @lufthansa My fight is in 3 days !!! last time I spoke to a rep 3 weeks ago, they said they would refund me in full, I got an email stating this would happen and nothing, why was I lied to ? They're rebooking for next 72hours so if I call in 4 days I will get a refund ?   \n",
       "3                1244685953983225857                                                                                                          @lufthansa I requested a refund back on 16/03 and I’m yet to receive any updates. I appreciate your busy I’ve tried calling numerous times for 2hrs plus. Could you give me an update?   \n",
       "                 1244689043952209921  @AndyHall52 Due to the sheer amount of refund requests needed to be initiated manually by my colleagues, we are unable to predict you with a time frame at the moment, unfortunately. Your patience is highly appreciated, as my colleagues will refund your ticket as soon as possible. /Susi   \n",
       "4                1244684192040071173          @lufthansa had an email stating changes to my reservation ( you have cancelled my last leg and leaves me stranded in frankfurt ) states about rearranging via phone, but how can I when can't get through, no mention of refund tho, however you've cancelled so im entitled !! Advise   \n",
       "                 1244688444162486273                                                                              @Holgate1987 At the moment, my colleagues in the Service Center are working on all re-bookings for the next 72 hours. Please reach out to them at a later stage to request a refund https://t.co/eRWyrKTFGQ. /Susi   \n",
       "                 1244688904957165571                   @lufthansa My fight is in 3 days !!! last time I spoke to a rep 3 weeks ago, they said they would refund me in full, I got an email stating this would happen and nothing, why was I lied to ? They're revoking for next 72hours so if I call in 4 days I will get a refund ?   \n",
       "5                1244683083623870466                                                                                           @lufthansa Hi, when can I expect a refund for a booking of mine, which you cancelled? I have been waiting for 2 weeks now.\\n\\nI have attempted to contact you via Phone and Email, but to no success.   \n",
       "                 1244687406735011841    @__01Alex Due to the sheer amount of refund requests needed to be initiated manually by my colleagues, we are unable to predict you with a time frame at the moment, unfortunately. Your patience is highly appreciated, as my colleagues will refund your ticket as soon as possible. /Susi   \n",
       "6                1242802417466576897              We were already able to bring 17,000 passengers back home, we are flying important humanitarian goods to wherever they are needed most, and we are taking care of your bookings. Thank you for your patience. Further information: https://t.co/Ne1bKLJj0A https://t.co/L39QksjCQB   \n",
       "                 1244687164467744773                                                                              @lufthansa Stop lying! Get bankrupt already. Otherwise I don’t see a reason why you steal people’s money! #Coronavirustruth #Covid_19 #theves #scamairline #scam #ScamAware #SCAM #fuckthisairline #whereismymoney   \n",
       "7                1243168721843216384              Physical distancing: Lufthansa introduces further distance rules. From tomorrow on all flights from Germany the neighbouring seats remain free. Arrivals &amp; departures in Germany only at gate positions to avoid bus shuttles. https://t.co/YtyRngk6n7 https://t.co/TpiPlSLXvi   \n",
       "                 1244686742420144130                                                                                                                   @lufthansa Before you make changes! Refund the money you owe to passengers you screwed over #fuckthisairline #scam #COVID19 #coronavirus #FAILED #fail20 #shitairline #theves   \n",
       "8                1244635094486138880                                                 @lufthansa  I booked my dream holiday to Rome (Italy) in January'2020 as a good passenger by making full payment before CARONA pandamic. After the outbreak happened, Indian government cancelled all international travel especially to Italy.   \n",
       "                 1244635963051008002              Then like a good citizen of india i cancelled my ticket on https://t.co/QUAssBVj5T the meantime @lufthansa changed my schedule without my knowledge and now they have changed policy of not giving refund of my ticket but credit. Please behave sensibly and give me full refund.   \n",
       "                 1244636899827806211                                 @lufthansa @Lufthansa_USA @lufthansaNews \\nI booked my tickets with you thinking that I can rest assured as @lufthansa is reputed company and never thought they will change their rules overnight. So request you to please help me in getting my full refund.   \n",
       "\n",
       "                                     lang     replied_tweet_id        category  \n",
       "New_Conversation Tweet_ID                                                       \n",
       "1                1244658051740774400   en  1244650317494566913   cancellations  \n",
       "                 1244688840033546245   en  1244658051740774400   cancellations  \n",
       "                 1244691330837762051   en  1244688840033546245   cancellations  \n",
       "2                1244684192040071173   en                 None  booking issues  \n",
       "                 1244688444162486273   en  1244684192040071173  booking issues  \n",
       "                 1244689066567794688   en  1244688444162486273  booking issues  \n",
       "3                1244685953983225857   en                 None         refunds  \n",
       "                 1244689043952209921   en  1244685953983225857         refunds  \n",
       "4                1244684192040071173   en                 None  booking issues  \n",
       "                 1244688444162486273   en  1244684192040071173  booking issues  \n",
       "                 1244688904957165571   en  1244688444162486273  booking issues  \n",
       "5                1244683083623870466   en                 None  booking issues  \n",
       "                 1244687406735011841   en  1244683083623870466  booking issues  \n",
       "6                1242802417466576897   en                 None  booking issues  \n",
       "                 1244687164467744773   en  1242802417466576897  booking issues  \n",
       "7                1243168721843216384   en                 None         refunds  \n",
       "                 1244686742420144130   en  1243168721843216384         refunds  \n",
       "8                1244635094486138880   en                 None   cancellations  \n",
       "                 1244635963051008002   en  1244635094486138880   cancellations  \n",
       "                 1244636899827806211   en  1244635963051008002   cancellations  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "test_airline_conversation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import XLMRobertaTokenizer, TFXLMRobertaForSequenceClassification\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('joeddav/xlm-roberta-large-xnli')\n",
    "model = TFXLMRobertaForSequenceClassification.from_pretrained('joeddav/xlm-roberta-large-xnli')\n",
    "\n",
    "\n",
    "#This is the example data you should feed into the model\n",
    "labeled_data = [\n",
    "    {\"tweet\": \"full_text 1\", \"labels\": [\"category1\"]},\n",
    "    {\"tweet\": \"full_text 2\", \"labels\": [\"category3\"]},\n",
    "]\n",
    "\n",
    "inputs = tokenizer([item[\"tweet\"] for item in labeled_data], padding=True, truncation=True, return_tensors=\"tf\")\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform([item[\"labels\"] for item in labeled_data])\n",
    "labels = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5), loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "#The model automatically saves in to your local directory after you run it once. For better performance\n",
    "#it is possible to adjust epoch size and batch_size, but i would not recommend it.\n",
    "\n",
    "model.fit(inputs, labels, epochs=3, batch_size=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jokubas/anaconda3/envs/new_fucking_env/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/81/hndg8mlx10316d7lgy0410jr0000gq/T/ipykernel_30773/2732759237.py:7: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    }
   ],
   "source": [
    "#Load the tokenizer and model once\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "#Check if GPU is available\n",
    "if tf.test.is_gpu_available():\n",
    "    device = '/GPU:0'\n",
    "else:\n",
    "    device = '/CPU:0'\n",
    "\n",
    "#Set the labels for sentiment results\n",
    "labels = {\n",
    "    0 : 'negative',\n",
    "    1 : 'neutral',\n",
    "    2 : 'positive'\n",
    "}\n",
    "\n",
    "def process_batch(texts):\n",
    "    \"\"\"\n",
    "    Apply sentiment analysis to a batch of texts using a pre-trained transformer model.\n",
    "\n",
    "    Parameters:\n",
    "    texts (list): A list of texts to analyze.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of ranked sentiment labels for the input texts.\n",
    "\n",
    "    This function uses a pre-trained transformer model for sequence classification to analyze the sentiment of the texts in the given batch. It returns a list of ranked sentiment labels for the input texts, where the first label is the most likely sentiment and the subsequent labels are less likely sentiments.\n",
    "    \"\"\"\n",
    "    encoded_input = tokenizer(texts, return_tensors='tf', padding=True, truncation=True)\n",
    "    with tf.device(device):\n",
    "        output = model(encoded_input)\n",
    "\n",
    "    scores = output[0].numpy()\n",
    "    scores = softmax(scores, axis=1)\n",
    "\n",
    "    sentiment_scores = scores[:, 2] - scores[:, 0]\n",
    "    return sentiment_scores.tolist()\n",
    "\n",
    "def apply_sentiment_analysis(df, text_column, batch_size=64, max_workers=4):\n",
    "    \"\"\"\n",
    "    Apply sentiment analysis to the given DataFrame using a pre-trained transformer model.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input DataFrame containing the text column to analyze.\n",
    "    text_column (str): The name of the column in the DataFrame containing the text to analyze.\n",
    "    batch_size (int): The number of texts to process in each batch. Default is 128.\n",
    "    max_workers (int): The maximum number of worker threads to use for parallel processing. Default is 4.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The input DataFrame with an additional 'sentiment' column containing the sentiment analysis results.\n",
    "\n",
    "    This function uses a pre-trained transformer model for sequence classification to analyze the sentiment of the texts in the given DataFrame. It applies the sentiment analysis in parallel using multiple worker threads to improve performance. The results are then added to the input DataFrame as a new 'sentiment' column.\n",
    "    \"\"\"\n",
    "    texts = df[text_column].tolist()\n",
    "    results = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i+batch_size]\n",
    "            results.extend(executor.submit(process_batch, batch).result())\n",
    "\n",
    "    df['sentiment'] = results\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/var/folders/81/hndg8mlx10316d7lgy0410jr0000gq/T/ipykernel_30773/2732759237.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment'] = results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New_Conversation</th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>1244658051740774400</th>\n",
       "      <td>@thick_daddy The online cancellation tool will only refund according to the fare conditions, Penelope. /Mac</td>\n",
       "      <td>-0.012933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244688840033546245</th>\n",
       "      <td>@lufthansa @thick_daddy I received the same email after cancelling and requesting a refund online (my flight segments had been cancelled by airline).  Are you able to check refund status, or do we have to call the service center?</td>\n",
       "      <td>-0.467777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244691330837762051</th>\n",
       "      <td>@NateThomasNOLA @thick_daddy At the moment, my colleagues in the Service Center are working on all re-bookings for the next 72 hours. Please reach out to them at a later stage to inquire about your refund status https://t.co/eRWyrKTFGQ. /Susi</td>\n",
       "      <td>-0.029740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>1244684192040071173</th>\n",
       "      <td>@lufthansa had an email stating changes to my reservation ( you have cancelled my last leg and leaves me stranded in frankfurt ) states about rearranging via phone, but how can I when can't get through, no mention of refund tho, however you've cancelled so im entitled !! Advise</td>\n",
       "      <td>-0.652843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244688444162486273</th>\n",
       "      <td>@Holgate1987 At the moment, my colleagues in the Service Center are working on all re-bookings for the next 72 hours. Please reach out to them at a later stage to request a refund https://t.co/eRWyrKTFGQ. /Susi</td>\n",
       "      <td>-0.124847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                   full_text  \\\n",
       "New_Conversation Tweet_ID                                                                                                                                                                                                                                                                                                      \n",
       "1                1244658051740774400                                                                                                                                                                             @thick_daddy The online cancellation tool will only refund according to the fare conditions, Penelope. /Mac   \n",
       "                 1244688840033546245                                                   @lufthansa @thick_daddy I received the same email after cancelling and requesting a refund online (my flight segments had been cancelled by airline).  Are you able to check refund status, or do we have to call the service center?   \n",
       "                 1244691330837762051                                      @NateThomasNOLA @thick_daddy At the moment, my colleagues in the Service Center are working on all re-bookings for the next 72 hours. Please reach out to them at a later stage to inquire about your refund status https://t.co/eRWyrKTFGQ. /Susi   \n",
       "2                1244684192040071173  @lufthansa had an email stating changes to my reservation ( you have cancelled my last leg and leaves me stranded in frankfurt ) states about rearranging via phone, but how can I when can't get through, no mention of refund tho, however you've cancelled so im entitled !! Advise   \n",
       "                 1244688444162486273                                                                      @Holgate1987 At the moment, my colleagues in the Service Center are working on all re-bookings for the next 72 hours. Please reach out to them at a later stage to request a refund https://t.co/eRWyrKTFGQ. /Susi   \n",
       "\n",
       "                                      sentiment  \n",
       "New_Conversation Tweet_ID                        \n",
       "1                1244658051740774400  -0.012933  \n",
       "                 1244688840033546245  -0.467777  \n",
       "                 1244691330837762051  -0.029740  \n",
       "2                1244684192040071173  -0.652843  \n",
       "                 1244688444162486273  -0.124847  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)  \n",
    "full_text_df = airline_conversation[['full_text']].copy()\n",
    "airline_conversation_sample = full_text_df.head(5)\n",
    "airline_conversation_sample = apply_sentiment_analysis(airline_conversation_sample, 'full_text')\n",
    "airline_conversation_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from typing import Tuple, List\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def connect_to_database(user: str, database: str, password: str, host: str):\n",
    "    \"\"\"\n",
    "    Establish a connection to the database.\n",
    "    \n",
    "    Args:\n",
    "        user: The database user.\n",
    "        database: The name of the database.\n",
    "        password: The password for the database.\n",
    "        host: The database host.\n",
    "    \n",
    "    Returns:\n",
    "        A connection object to the MySQL database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            user=user,\n",
    "            password=password,\n",
    "            host=host,\n",
    "            database=database\n",
    "        )\n",
    "        if connection.is_connected():\n",
    "            return connection\n",
    "    except Error as e:\n",
    "        print(f\"Error while connecting to MySQL: {e}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_batches(df: pd.DataFrame, batch_size: int = 1000) -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Split DataFrame into batches of DataFrames with specified batch size.\n",
    "    \n",
    "    Args:\n",
    "        df: The DataFrame containing tweet data.\n",
    "        batch_size: The size of each batch.\n",
    "        \n",
    "    Returns:\n",
    "        A list of DataFrames, each containing a batch of rows.\n",
    "    \"\"\"\n",
    "    return [df.iloc[i:i + batch_size] for i in range(0, len(df), batch_size)]\n",
    "\n",
    "def update_sentiment_batch(user: str, database: str, password: str, host: str, batch: List[Tuple[str, float]]):\n",
    "    \"\"\"\n",
    "    Update sentiment values for a batch of data in the database.\n",
    "    \n",
    "    Args:\n",
    "        user: The database user.\n",
    "        database: The name of the database.\n",
    "        password: The password for the database.\n",
    "        host: The database host.\n",
    "        batch: A list of tuples containing tweet_id and sentiment.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        connection = connect_to_database(user, database, password, host)\n",
    "        if connection is None:\n",
    "            return\n",
    "        cursor = connection.cursor()\n",
    "        update_query = \"UPDATE Tweets SET sentiment_score = %s WHERE tweet_id = %s\"\n",
    "        cursor.executemany(update_query, batch)\n",
    "        connection.commit()\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "    except Error as e:\n",
    "        print(f\"Error updating batch: {e}\")\n",
    "\n",
    "def upload_sentiment(batch: Tuple[Tuple[float, str]],\n",
    "                     user: str, database: str, password: str,\n",
    "                     host: str) -> None:\n",
    "    \"\"\"\n",
    "    Create and insert batches of tweets into the database in parallel.\n",
    "    \n",
    "    Args:\n",
    "        batches_list: Tuple of (sentiment, tweet_id) pairs.\n",
    "        user: The database user.\n",
    "        database: The name of the database.\n",
    "        password: The password for the database.\n",
    "        host: The database host.\n",
    "    \"\"\"\n",
    "    connection = connect_to_database(user, database, password, host)\n",
    "    if connection is None:\n",
    "        return\n",
    "    cursor = connection.cursor()\n",
    "    update_query = \"UPDATE Tweets SET sentiment_score = %s WHERE tweet_id = %s\"\n",
    "    cursor.executemany(update_query, batch)\n",
    "    connection.commit()\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "\n",
    "    print(\"Sentiment values updated successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(df: pd.DataFrame) -> List[List]:\n",
    "    \"\"\"\n",
    "    Convert DataFrame with tweet_id as index to a list of lists containing sentiment and tweet_id.\n",
    "    \n",
    "    Args:\n",
    "        df: The DataFrame with tweet_id as index and sentiment as a column.\n",
    "        \n",
    "    Returns:\n",
    "        A list of lists containing tweet_id and sentiment.\n",
    "    \"\"\"\n",
    "    tweet_ids = df.index.to_numpy()\n",
    "    sentiments = df['sentiment'].to_numpy()\n",
    "    return tuple(zip(sentiments, tweet_ids))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_batches \u001b[38;5;241m=\u001b[39m get_batches(test_data[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]], \u001b[38;5;241m10_000\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_fucking_env/lib/python3.11/site-packages/pandas/core/frame.py:4105\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m   4103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice(indexer, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m-> 4105\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take_with_is_copy(indexer, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   4107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[1;32m   4108\u001b[0m     \u001b[38;5;66;03m# What does looking for a single key in a non-unique index return?\u001b[39;00m\n\u001b[1;32m   4109\u001b[0m     \u001b[38;5;66;03m# The behavior is inconsistent. It returns a Series, except when\u001b[39;00m\n\u001b[1;32m   4110\u001b[0m     \u001b[38;5;66;03m# - the key itself is repeated (test on data.shape, #9519), or\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m     \u001b[38;5;66;03m# - we have a MultiIndex on columns (test on self.columns, #21309)\u001b[39;00m\n\u001b[1;32m   4112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n\u001b[1;32m   4113\u001b[0m         \u001b[38;5;66;03m# GH#26490 using data[key] can cause RecursionError\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_fucking_env/lib/python3.11/site-packages/pandas/core/generic.py:4150\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4139\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   4140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   4141\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4142\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   4143\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4148\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   4149\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4150\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indices\u001b[38;5;241m=\u001b[39mindices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   4151\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   4152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m~/anaconda3/envs/new_fucking_env/lib/python3.11/site-packages/pandas/core/generic.py:4130\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4125\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[1;32m   4126\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4127\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4128\u001b[0m     )\n\u001b[0;32m-> 4130\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mtake(\n\u001b[1;32m   4131\u001b[0m     indices,\n\u001b[1;32m   4132\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis),\n\u001b[1;32m   4133\u001b[0m     verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   4134\u001b[0m )\n\u001b[1;32m   4135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4136\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4137\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/new_fucking_env/lib/python3.11/site-packages/pandas/core/internals/managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[1;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[1;32m    895\u001b[0m     new_axis\u001b[38;5;241m=\u001b[39mnew_labels,\n\u001b[1;32m    896\u001b[0m     indexer\u001b[38;5;241m=\u001b[39mindexer,\n\u001b[1;32m    897\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m    898\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    899\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    900\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/new_fucking_env/lib/python3.11/site-packages/pandas/core/internals/managers.py:680\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    681\u001b[0m         indexer,\n\u001b[1;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[1;32m    689\u001b[0m             indexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    696\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/envs/new_fucking_env/lib/python3.11/site-packages/pandas/core/internals/managers.py:843\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy, ref_inplace_op)\u001b[0m\n\u001b[1;32m    841\u001b[0m                     blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[1;32m    842\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 843\u001b[0m                 nb \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mtake_nd(taker, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, new_mgr_locs\u001b[38;5;241m=\u001b[39mmgr_locs)\n\u001b[1;32m    844\u001b[0m                 blocks\u001b[38;5;241m.\u001b[39mappend(nb)\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m blocks\n",
      "File \u001b[0;32m~/anaconda3/envs/new_fucking_env/lib/python3.11/site-packages/pandas/core/internals/blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[0;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m algos\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[1;32m   1308\u001b[0m     values, indexer, axis\u001b[38;5;241m=\u001b[39maxis, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill, fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[1;32m   1309\u001b[0m )\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/new_fucking_env/lib/python3.11/site-packages/pandas/core/array_algos/take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[1;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[0;32m~/anaconda3/envs/new_fucking_env/lib/python3.11/site-packages/pandas/core/array_algos/take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[1;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[1;32m    161\u001b[0m )\n\u001b[0;32m--> 162\u001b[0m func(arr, indexer, out, fill_value)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[1;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_batches = get_batches(test_data[[\"full_text\"]], 10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user, database, password, host = os.getenv(\"DBL_USER\"), os.getenv(\"DBL_DATABASE\"), os.getenv(\"DBL_PASSWORD\"), os.getenv(\"DBL_HOST\")\n",
    "for batch in tqdm(data_batches):\n",
    "    sentiment_with_score = apply_sentiment_analysis(batch, \"full_text\")\n",
    "    upload_sentiment(convert_to_list(sentiment_with_score), user, database, password, host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
